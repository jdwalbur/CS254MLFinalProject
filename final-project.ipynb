{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import chess.pgn\n",
    "import chess.engine\n",
    "import csv\n",
    "import os.path\n",
    "import io\n",
    "import re\n",
    "import subprocess\n",
    "import platform\n",
    "import timeit\n",
    "import random\n",
    "import datetime\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from textwrap import wrap\n",
    "from typing import List, Tuple, Generator, Union, Optional\n",
    "import pyperclip as pc  # TODO remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Machine Learning\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as ks\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as skl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Python chess basics\n",
    "https://python-chess.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Sample PGN Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "jackson_pgn = '''\n",
    "[Event \"Rated Bullet game\"]\n",
    "[Site \"https://lichess.org/69CbaD8f\"]\n",
    "[Date \"2021.10.07\"]\n",
    "[White \"Cubigami\"]\n",
    "[Black \"JoinedToday\"]\n",
    "[Result \"1-0\"]\n",
    "[UTCDate \"2021.10.07\"]\n",
    "[UTCTime \"05:16:00\"]\n",
    "[WhiteElo \"1930\"]\n",
    "[BlackElo \"1912\"]\n",
    "[WhiteRatingDiff \"+5\"]\n",
    "[BlackRatingDiff \"-6\"]\n",
    "[Variant \"Standard\"]\n",
    "[TimeControl \"60+0\"]\n",
    "[ECO \"B01\"]\n",
    "[Opening \"Scandinavian Defense: Mieses-Kotroc Variation\"]\n",
    "[Termination \"Normal\"]\n",
    "[Annotator \"lichess.org\"]\n",
    "\n",
    "1. e4 { [%eval 0.24] [%clk 0:01:00] } 1... d5?! { (0.24 → 0.82) Inaccuracy. e5 was best. } { [%eval 0.82] [%clk 0:01:00] } (1... e5 2. Nf3 Nc6 3. Bb5 Nf6 4. O-O Nxe4 5. Re1 Nd6 6. Nxe5) 2. exd5 { [%eval 0.36] [%clk 0:01:00] } 2... Qxd5 { [%eval 0.66] [%clk 0:01:00] } { B01 Scandinavian Defense: Mieses-Kotroc Variation } 3. Nc3 { [%eval 0.46] [%clk 0:01:00] } 3... Qe6+?! { (0.46 → 1.12) Inaccuracy. Qa5 was best. } { [%eval 1.12] [%clk 0:01:00] } (3... Qa5 4. Nf3 Nf6 5. d4 Bf5 6. Ne5 c6 7. Bf4 Nbd7 8. Nc4) 4. Be2 { [%eval 0.94] [%clk 0:00:59] } 4... Qg6? { (0.94 → 2.18) Mistake. Nf6 was best. } { [%eval 2.18] [%clk 0:01:00] } (4... Nf6 5. d4 Qd6 6. Nf3 e6 7. O-O Be7 8. Nb5 Qd8 9. c4) 5. Nf3 { [%eval 1.51] [%clk 0:00:58] } 5... Nc6?? { (1.51 → 4.52) Blunder. Qxg2 was best. } { [%eval 4.52] [%clk 0:00:59] } (5... Qxg2 6. Rg1 Qh3 7. d4 Nf6 8. Rg3 Qf5 9. Ne5 c6 10. Rf3) 6. O-O?? { (4.52 → 0.37) Blunder. Nb5 was best. } { [%eval 0.37] [%clk 0:00:57] } (6. Nb5 Kd8 7. d4 a6 8. d5 axb5 9. dxc6+ Ke8 10. Ne5 Qe6) 6... h5?? { (0.37 → 5.60) Blunder. Bh3 was best. } { [%eval 5.6] [%clk 0:00:59] } (6... Bh3 7. Ne1 Bf5 8. Nd5 O-O-O 9. Ne3 Nf6 10. Nf3 Be4 11. d3) 7. h4?? { (5.60 → 0.08) Blunder. Nb5 was best. } { [%eval 0.08] [%clk 0:00:56] } (7. Nb5 Bh3) 7... a6?? { (0.08 → 2.63) Blunder. Bh3 was best. } { [%eval 2.63] [%clk 0:00:58] } (7... Bh3 8. Ng5 Bf5 9. Bb5 f6 10. Nf3 e6 11. Nd4 Ne7 12. Qf3 Kd7 13. Re1 a6 14. Ba4) 8. Bd3?? { (2.63 → -0.22) Blunder. d4 was best. } { [%eval -0.22] [%clk 0:00:53] } (8. d4) 8... Qf6?? { (-0.22 → 1.46) Blunder. Bf5 was best. } { [%eval 1.46] [%clk 0:00:56] } (8... Bf5) 9. Ne4 { [%eval 1.24] [%clk 0:00:51] } 9... Qe6?! { (1.24 → 2.16) Inaccuracy. Qg6 was best. } { [%eval 2.16] [%clk 0:00:54] } (9... Qg6 10. Ng3) 10. Nfg5? { (2.16 → 0.77) Mistake. Neg5 was best. } { [%eval 0.77] [%clk 0:00:51] } (10. Neg5 Qd6 11. Bc4 Nh6 12. c3 Bf5 13. Qb3 O-O-O 14. Bxf7 e5 15. Be6+ Bxe6 16. Qxe6+ Qxe6) 10... Qd7?? { (0.77 → 8.62) Blunder. Qd5 was best. } { [%eval 8.62] [%clk 0:00:52] } (10... Qd5 11. Nc3 Qd8 12. Bc4 e6 13. Re1 Be7 14. d3 Nh6 15. Qxh5 g6 16. Qd1 Nf5 17. g3) 11. Qf3?? { (8.62 → -0.59) Blunder. Nxf7 was best. } { [%eval -0.59] [%clk 0:00:50] } (11. Nxf7) 11... f6?? { (-0.59 → 8.00) Blunder. Ne5 was best. } { [%eval 8.0] [%clk 0:00:50] } (11... Ne5 12. Qf4 f6 13. Be2 Nc6 14. Nf3 e5 15. Qe3 Nge7 16. Qb3 Qd5 17. d3 Qxb3 18. axb3) 12. Nc5 { [%eval 7.68] [%clk 0:00:47] } 12... Qd8? { (7.68 → Mate in 1) Checkmate is now unavoidable. Ne5 was best. } { [%eval #1] [%clk 0:00:49] } (12... Ne5 13. Bg6+ Nxg6 14. Nxd7 Bxd7 15. Qxb7 Rd8 16. Qe4 Nxh4 17. Ne6 Bxe6 18. Qxe6 Rd6 19. Qc4) 13. Nge6? { (Mate in 1 → 8.51) Lost forced checkmate sequence. Bg6# was best. } { [%eval 8.51] [%clk 0:00:45] } (13. Bg6#) 13... Bxe6 { [%eval 8.53] [%clk 0:00:43] } 14. Nxe6 { [%eval 8.78] [%clk 0:00:45] } 14... Qd7? { (8.78 → Mate in 1) Checkmate is now unavoidable. Ne5 was best. } { [%eval #1] [%clk 0:00:43] } (14... Ne5 15. Qxb7) 15. Bg6# { [%clk 0:00:45] } { White wins by checkmate. } 1-0'''\n",
    "\n",
    "carlson_pgn = '''\n",
    "[Event \"Rated Blitz game\"]\n",
    "[Site \"https://lichess.org/RzGPtofJ\"]\n",
    "[Date \"2021.08.19\"]\n",
    "[White \"Feokl1995\"]\n",
    "[Black \"DrNykterstein\"]\n",
    "[Result \"1/2-1/2\"]\n",
    "[UTCDate \"2021.08.19\"]\n",
    "[UTCTime \"22:35:41\"]\n",
    "[WhiteElo \"2998\"]\n",
    "[BlackElo \"3141\"]\n",
    "[WhiteRatingDiff \"+2\"]\n",
    "[BlackRatingDiff \"-2\"]\n",
    "[WhiteTitle \"GM\"]\n",
    "[BlackTitle \"GM\"]\n",
    "[Variant \"Standard\"]\n",
    "[TimeControl \"180+0\"]\n",
    "[ECO \"B00\"]\n",
    "[Opening \"Nimzowitsch Defense: Williams Variation\"]\n",
    "[Termination \"Normal\"]\n",
    "[Annotator \"lichess.org\"]\n",
    "\n",
    "1. e4 { [%eval 0.24] [%clk 0:03:00] } 1... Nc6 { [%eval 0.44] [%clk 0:03:00] } 2. Nf3 { [%eval 0.24] [%clk 0:02:58] } 2... d6 { [%eval 0.71] [%clk 0:02:59] } { B00 Nimzowitsch Defense: Williams Variation } 3. d4 { [%eval 0.72] [%clk 0:02:57] } 3... Nf6 { [%eval 0.89] [%clk 0:02:58] } 4. Nc3 { [%eval 0.54] [%clk 0:02:56] } 4... g6 { [%eval 0.96] [%clk 0:02:58] } 5. h3?! { (0.96 → 0.42) Inaccuracy. Be3 was best. } { [%eval 0.42] [%clk 0:02:55] } (5. Be3 Bg7 6. Qd2 O-O 7. d5 Nb8 8. Bh6 c6 9. h3 b5) 5... Bg7 { [%eval 0.67] [%clk 0:02:57] } 6. Be2 { [%eval 0.5] [%clk 0:02:55] } 6... O-O { [%eval 0.5] [%clk 0:02:57] } 7. O-O { [%eval 0.34] [%clk 0:02:54] } 7... a6 { [%eval 0.4] [%clk 0:02:55] } 8. a4 { [%eval 0.53] [%clk 0:02:53] } 8... b6 { [%eval 0.62] [%clk 0:02:50] } 9. Be3 { [%eval 0.39] [%clk 0:02:52] } 9... e6 { [%eval 0.6] [%clk 0:02:47] } 10. e5 { [%eval 0.84] [%clk 0:02:41] } 10... dxe5 { [%eval 0.56] [%clk 0:02:46] } 11. Nxe5 { [%eval 0.57] [%clk 0:02:40] } 11... Bb7 { [%eval 0.73] [%clk 0:02:43] } 12. Bf3 { [%eval 0.81] [%clk 0:02:38] } 12... Nd5 { [%eval 0.91] [%clk 0:02:42] } 13. Nxd5 { [%eval 0.85] [%clk 0:02:36] } 13... exd5 { [%eval 0.75] [%clk 0:02:42] } 14. Nxc6 { [%eval 0.81] [%clk 0:02:31] } 14... Bxc6 { [%eval 0.87] [%clk 0:02:42] } 15. c3 { [%eval 0.75] [%clk 0:02:30] } 15... a5 { [%eval 1.03] [%clk 0:02:41] } 16. Bf4 { [%eval 0.6] [%clk 0:02:29] } 16... Qd7 { [%eval 0.88] [%clk 0:02:40] } 17. Re1 { [%eval 0.75] [%clk 0:02:28] } 17... Rfe8 { [%eval 0.79] [%clk 0:02:39] } 18. b3 { [%eval 0.36] [%clk 0:02:26] } 18... Rxe1+ { [%eval 0.35] [%clk 0:02:37] } 19. Qxe1 { [%eval 0.45] [%clk 0:02:26] } 19... Re8 { [%eval 0.42] [%clk 0:02:36] } 20. Qd2 { [%eval 0.55] [%clk 0:02:26] } 20... Bf8 { [%eval 0.36] [%clk 0:02:36] } 21. Re1 { [%eval 0.28] [%clk 0:02:19] } 21... Rxe1+ { [%eval 0.29] [%clk 0:02:35] } 22. Qxe1 { [%eval 0.45] [%clk 0:02:19] } 22... Bd6 { [%eval 0.25] [%clk 0:02:34] } 23. Qe3 { [%eval 0.22] [%clk 0:02:17] } 23... f6 { [%eval 0.42] [%clk 0:02:12] } 24. Bg4 { [%eval 0.14] [%clk 0:02:12] } 24... Qd8 { [%eval 0.63] [%clk 0:02:09] } 25. Qe6+ { [%eval 0.44] [%clk 0:02:10] } 25... Kg7 { [%eval 0.47] [%clk 0:02:07] } 26. Bxd6 { [%eval 0.4] [%clk 0:02:08] } 26... Qxd6 { [%eval 0.43] [%clk 0:02:07] } 27. Qxd6 { [%eval 0.42] [%clk 0:02:06] } 27... cxd6 { [%eval 0.43] [%clk 0:02:07] } 28. Bf3 { [%eval 0.45] [%clk 0:02:02] } 28... f5 { [%eval 0.43] [%clk 0:02:06] } 29. h4 { [%eval 0.21] [%clk 0:01:55] } 29... Kf6 { [%eval 0.21] [%clk 0:02:04] } 30. g3 { [%eval 0.26] [%clk 0:01:54] } 30... h6 { [%eval 0.36] [%clk 0:02:03] } 31. Be2 { [%eval 0.14] [%clk 0:01:51] } 31... Bd7 { [%eval 0.3] [%clk 0:01:59] } 32. f4 { [%eval 0.35] [%clk 0:01:50] } 32... h5 { [%eval 0.36] [%clk 0:01:58] } 33. Kf2 { [%eval 0.35] [%clk 0:01:50] } 33... Be6 { [%eval 0.34] [%clk 0:01:57] } 34. Ke3 { [%eval 0.34] [%clk 0:01:48] } 34... Ke7 { [%eval 0.29] [%clk 0:01:57] } 35. Kd2 { [%eval 0.21] [%clk 0:01:48] } 35... Kd8 { [%eval 0.34] [%clk 0:01:57] } 36. Bb5 { [%eval 0.32] [%clk 0:01:46] } 36... Bf7 { [%eval 0.19] [%clk 0:01:55] } 37. Kd3 { [%eval 0.19] [%clk 0:01:44] } 37... Kc7 { [%eval 0.26] [%clk 0:01:55] } 38. Ke3 { [%eval 0.39] [%clk 0:01:39] } 38... Kd8 { [%eval 0.35] [%clk 0:01:54] } 39. Kd2 { [%eval 0.52] [%clk 0:01:39] } 39... Kc7 { [%eval 0.36] [%clk 0:01:53] } 40. Kc2 { [%eval 0.23] [%clk 0:01:38] } 40... Kd8 { [%eval 0.3] [%clk 0:01:53] } 41. Kb2 { [%eval 0.25] [%clk 0:01:37] } 41... Kc7 { [%eval 0.27] [%clk 0:01:53] } 42. Kc2 { [%eval 0.34] [%clk 0:01:37] } 42... Kd8 { [%eval 0.17] [%clk 0:01:52] } 43. Kd2 { [%eval 0.33] [%clk 0:01:36] } 43... Kc7 { [%eval 0.17] [%clk 0:01:52] } { The game is a draw. } 1/2-1/2\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Export Only the Valid Games in New PGN\n",
    "Filter the games from Lichess's .pgn downloads to a new .pgn that only include games that are analyzed and have the tags in the game header that will be necessary for feature generation.\n",
    "\n",
    "Only ~20% of the original Sep. 2015 PGN download are valid games. Exporting only these games to a new file will save time generating data later for learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "''' Helper Functions'''\n",
    "\n",
    "DEFAULT_ERROR_MSG = 'Please enter \"y\" or \"n\".'\n",
    "def validate_yn(prompt: str, error_msg: str = DEFAULT_ERROR_MSG) -> bool:\n",
    "    \"\"\" Get a yes/no answer. \"\"\"\n",
    "    response = input(prompt)\n",
    "    while response.lower() not in ('y', 'yes', 'ya', 'n', 'no', 'nah'):\n",
    "        print(error_msg)\n",
    "        response = input(prompt)\n",
    "    return response.lower() in ('y', 'yes')\n",
    "\n",
    "def is_valid_analyzed_game(game: chess.pgn.Game) -> bool:\n",
    "    \"\"\" Return True if certain conditions about the Game are met. \"\"\"\n",
    "    # Must have these tags to use as features later\n",
    "    REQUIRED_TAGS = ('WhiteElo', 'BlackElo', 'TimeControl')\n",
    "    if not all((tag in game.headers for tag in REQUIRED_TAGS)):\n",
    "        return False\n",
    "\n",
    "    # Filter correspondence games (time controls like 3 days/move)\n",
    "    if game.headers['TimeControl'] == '-':\n",
    "        return False\n",
    "\n",
    "    # Make sure game has at least 2 moves in mainline\n",
    "    for ply, node in enumerate(game.mainline()):\n",
    "        # Don't return unanalyzed games\n",
    "        if ply == 0:\n",
    "            if '%eval' not in node.comment:\n",
    "                return False\n",
    "        else:\n",
    "            # Reached the second ply, skip \"else\"\n",
    "            break\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "''' Main Cleaning Function '''\n",
    "\n",
    "FILTER_GAMES_WRITE_BATCH_SIZE = 10_000\n",
    "def export_valid_games(pgn_filename: str,\n",
    "                       output_pgn_filename: str = None,\n",
    "                       max_games: Optional[int] = 1_000_000) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Export a new file containing PGN strings for only the games in pgn_filename\n",
    "    that are analyzed and have necessary info in the headers. The name of the new file\n",
    "    will be the same as pgn_filename but with \"___cleaned\" appended. This should be run\n",
    "    rarely to generate a new PGN file of the games we will be able to work with (and\n",
    "    will print a warning if the output filename already exists).\n",
    "\n",
    "    :param pgn_filename: The input filename\n",
    "    :param output_pgn_filename: If set, the new PGN filename. Set to None to autogenerate\n",
    "    :param max_games: Maximum number of games to write to the new file\n",
    "    :return: The name of the newly-generated file\n",
    "    \"\"\"\n",
    "\n",
    "    # PGN input file is required\n",
    "    assert os.path.splitext(pgn_filename)[1].lower() == '.pgn'\n",
    "\n",
    "    # Set filename if it wasn't given\n",
    "    if output_pgn_filename is None:\n",
    "        # Set the new name to be the input filename with ___cleaned\n",
    "        name, extension = os.path.splitext(pgn_filename)\n",
    "        output_pgn_filename = name + '___cleaned' + extension\n",
    "    else:\n",
    "        assert os.path.splitext(output_pgn_filename)[1].lower() == '.pgn'\n",
    "\n",
    "    # Warn if overwriting\n",
    "    if os.path.exists(output_pgn_filename):\n",
    "        if not validate_yn(f'warning: {output_pgn_filename} will be overwritten even though its size is '\n",
    "                           f'{os.path.getsize(output_pgn_filename) / 1e6:.2f}Mb. Continue? (y/n)'):\n",
    "            print('Aborting.')\n",
    "            return output_pgn_filename\n",
    "\n",
    "    # Extract the valid games\n",
    "    print(f'{datetime.datetime.now()}: Extracting valid games...')\n",
    "    start_time = timeit.default_timer()\n",
    "    with open(pgn_filename, 'r') as file:\n",
    "        num_games_checked = 0\n",
    "        total_num_valid_games_found = 0\n",
    "        num_valid_games_stored = 0\n",
    "        valid_games: List[str] = []\n",
    "\n",
    "        output_file_started = False\n",
    "\n",
    "        break_outer = False\n",
    "        while not break_outer:\n",
    "            # Get game\n",
    "            game = chess.pgn.read_game(file)\n",
    "            if game is None:\n",
    "                # No more games left, write whatever remains and break\n",
    "                print(f'{datetime.datetime.now()}: Writing {num_valid_games_stored} PGNs (total {total_num_valid_games_found})...', end='')\n",
    "                with open(output_pgn_filename, ('w', 'a')[output_file_started]) as f:\n",
    "                    f.write('\\n\\n\\n'.join(valid_games) + '\\n')\n",
    "                print('done.')\n",
    "                break\n",
    "\n",
    "            # Skip invalid games\n",
    "            is_valid = is_valid_analyzed_game(game)\n",
    "            num_games_checked += 1\n",
    "            if not is_valid:\n",
    "                continue\n",
    "\n",
    "            # Add to list\n",
    "            valid_games.append(str(game))\n",
    "            total_num_valid_games_found += 1\n",
    "            num_valid_games_stored += 1\n",
    "\n",
    "            # Wrap in try/else in case of PermissionError\n",
    "            break_inner = False\n",
    "            while not break_inner:\n",
    "                try:\n",
    "                    # Export list if current length > threshold (the elif)\n",
    "                    # or if we have enough now to write max_games PGNs (the if)\n",
    "                    if max_games is not None and total_num_valid_games_found == max_games \\\n",
    "                            or num_valid_games_stored >= FILTER_GAMES_WRITE_BATCH_SIZE:\n",
    "                        # Write all PGNs and break\n",
    "                        print(f'{datetime.datetime.now()}: Writing {num_valid_games_stored} PGNs (total {total_num_valid_games_found})...', end='')\n",
    "                        with open(output_pgn_filename, ('w', 'a')[output_file_started]) as f:\n",
    "                            f.write(''.join(pgn + '\\n\\n\\n' for pgn in valid_games))\n",
    "                        print('done.')\n",
    "                        break_outer = True\n",
    "                    elif num_valid_games_stored >= FILTER_GAMES_WRITE_BATCH_SIZE:\n",
    "                        # Write all PGNs\n",
    "                        print(f'{datetime.datetime.now()}: Writing {num_valid_games_stored} PGNs (total {total_num_valid_games_found})...', end='')\n",
    "                        with open(output_pgn_filename, ('w', 'a')[output_file_started]) as f:\n",
    "                            f.write(''.join(pgn + '\\n\\n\\n' for pgn in valid_games))\n",
    "                        print('done.')\n",
    "\n",
    "                        # Reset valid games list to free up memory\n",
    "                        valid_games = []\n",
    "                        num_valid_games_stored = 0\n",
    "                        output_file_started = True\n",
    "                    break_inner = True\n",
    "                except PermissionError:\n",
    "                    input(f'warning: PermissionError while saving. Please close {output_pgn_filename} and press enter.')\n",
    "\n",
    "    print()\n",
    "    print('Results:')\n",
    "    print(f'\\t{total_num_valid_games_found:,} valid PGNs written to \"{output_pgn_filename}\" '\n",
    "          f'({os.path.getsize(output_pgn_filename) / 1e6:.2f}Mb)')\n",
    "    print(f'\\t{num_games_checked:,} games checked for validity '\n",
    "          f'({total_num_valid_games_found/num_games_checked:.2%} valid)')\n",
    "    print(f'\\t{timeit.default_timer() - start_time:.2f}s elapsed')\n",
    "\n",
    "    return output_pgn_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The next cell will take a few hours to finish if `max_games=None`. It should have time if left running overnight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aborting.\n"
     ]
    }
   ],
   "source": [
    "RAW_PGN_FILENAME = 'data/lichess_db_standard_rated_2015-09.pgn'\n",
    "CLEANED_PGN_FILENAME = export_valid_games(RAW_PGN_FILENAME, max_games=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Helper Functions for Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generate_games(pgn_filename: str,\n",
    "                   max_games: int = 1_000_000,\n",
    "                   validate: bool = False) -> Generator[str, None, None]:\n",
    "    \"\"\"\n",
    "    Take a PGN filename and return a generator that loops over the first num_games games. If\n",
    "    validate is True, check whether a game is valid before yielding it (set to False if using\n",
    "    a \"...___cleaned.pgn\" input file).\n",
    "    \"\"\"\n",
    "    with open(pgn_filename, 'r') as file:\n",
    "        num_games_yielded = 0\n",
    "        while True:\n",
    "            if num_games_yielded > max_games:\n",
    "                return\n",
    "\n",
    "            game = chess.pgn.read_game(file)\n",
    "\n",
    "            # No more games in the PGN\n",
    "            if game is None:\n",
    "                return\n",
    "\n",
    "            # No need to check for validity here if using ...___cleaned.pgn file\n",
    "            if validate:\n",
    "                if not is_valid_analyzed_game(game):\n",
    "                    continue\n",
    "\n",
    "            yield game\n",
    "            num_games_yielded += 1\n",
    "\n",
    "EVAL_REGEX_PAT = '\\[%eval ([+-]?(?:[0-9]*[.])?[0-9]+|#-?[0-9]+)]'\n",
    "def get_score_from_comment(comment: str) -> float:\n",
    "    \"\"\" Return the pawn-score in the comment if it contains \"%eval\". If \"%eval\" not in comment, raises ValueError. \"\"\"\n",
    "    if '%eval' not in comment:\n",
    "        raise ValueError\n",
    "\n",
    "    # Get score part using regex\n",
    "    evals = re.findall(EVAL_REGEX_PAT, comment)\n",
    "    assert len(evals) == 1, f'error: \"%eval\" tag does not appear exactly once in move.comment = {comment}'\n",
    "    score = evals[0]\n",
    "\n",
    "    # Convert to float\n",
    "    try:\n",
    "        score = float(score)\n",
    "    except ValueError:\n",
    "        # Only explanation for ValueError should be that %eval's score is a checkmate, ex. '#-5' or '#9'\n",
    "        # Convert to centipawn-score with mate_score, then /100 to get pawn-score\n",
    "        # https://python-chess.readthedocs.io/en/latest/engine.html?highlight=mate_score#chess.engine.Score.score\n",
    "        assert '#' in score\n",
    "        score = chess.engine.Mate(int(score.lstrip('#'))).score(mate_score=10_000) / 100.0\n",
    "    return score\n",
    "\n",
    "CLK_REGEX_PAT = '\\[%clk (.*?)]'\n",
    "def get_time_remaining_from_comment(comment: str) -> int:\n",
    "    \"\"\"\n",
    "    Return the time remaining in seconds given by the \"%clk\" tag in the comment (always appears as an int).\n",
    "    If \"%clk\" not in comment, raise ValueError.\n",
    "    \"\"\"\n",
    "    if '%clk' not in comment:\n",
    "        raise ValueError\n",
    "\n",
    "    # Get eval part using regex\n",
    "    clk = re.findall(CLK_REGEX_PAT, comment)\n",
    "    assert len(clk) == 1, f'error: \"%clk\" tag does not appear exactly once in move.comment = {comment}'\n",
    "    clk = clk[0]\n",
    "\n",
    "    parts = clk.split(':')\n",
    "    assert len(parts) == 3\n",
    "    seconds_remaining = int(parts[0]) * 3600 \\\n",
    "                     + int(parts[1]) * 60 \\\n",
    "                     + int(parts[2])\n",
    "    return seconds_remaining\n",
    "\n",
    "def get_cpl(from_score: float, to_score: float, after_move_by: chess.Color) -> int:\n",
    "    \"\"\" Get centipawn loss (CPL) based on scores of consecutive moves and the side to move. \"\"\"\n",
    "    return round((from_score - to_score) * 100) * (1 if after_move_by == chess.WHITE else -1)\n",
    "\n",
    "def parse_time_control(time_control: str) -> Tuple[int, int]:\n",
    "    \"\"\" Convert a time control string like \"300+3\" . \"\"\"\n",
    "    if time_control == '-':\n",
    "        # Correspondence game (ex. 3 days per move)\n",
    "        # Assume the longest time control of 120+120\n",
    "        return 7200, 120\n",
    "\n",
    "    x = time_control.split('+')\n",
    "    return int(x[0]), int(x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Engine Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def start_engine_process() -> Generator[subprocess.Popen, None, None]:\n",
    "    # Set Stockfish file according to OS\n",
    "    system = platform.system()\n",
    "    if system == 'Darwin':\n",
    "        stockfish = './stockfish'\n",
    "    elif system == 'Windows':\n",
    "        stockfish = 'stockfish_14_x64_avx2.exe'\n",
    "    else:\n",
    "        raise OSError(f'error: Unsupported operating system {system}')\n",
    "\n",
    "    # Open the exe using Popen\n",
    "    p = subprocess.Popen(stockfish,\n",
    "                         stdin=subprocess.PIPE,\n",
    "                         stdout=subprocess.PIPE,\n",
    "                         stderr=subprocess.PIPE)\n",
    "\n",
    "    # Send commands to this open process by using stdin.write(*command*)\n",
    "    send_commands(p, 'isready\\n')\n",
    "\n",
    "    # Allows for \"with start_engine_process() as p: ...\"\n",
    "    try:\n",
    "        yield p\n",
    "    finally:\n",
    "        p.terminate()\n",
    "\n",
    "def send_commands(p: subprocess.Popen, *commands: str) -> None:\n",
    "    if not commands:\n",
    "        return\n",
    "\n",
    "    for cmd in commands:\n",
    "        p.stdin.write(cmd.encode())\n",
    "\n",
    "    p.stdin.flush()\n",
    "\n",
    "def analyze_static(p: subprocess.Popen, fen: str) -> str:\n",
    "    \"\"\" Return the full string output of Stockfish's static evaluation for the given FEN. \"\"\"\n",
    "\n",
    "    send_commands(p, f'position fen {fen}\\n', 'eval\\n')\n",
    "\n",
    "    # Get as many str lines as were output\n",
    "    lines = []\n",
    "    while True:\n",
    "        line = p.stdout.readline().decode().strip()\n",
    "        lines.append(line.strip('\\n\\r'))\n",
    "\n",
    "        # Static eval does not run on positions where either king is in check\n",
    "        if 'none (in check)' in line or 'Final evaluation' in line:\n",
    "            break\n",
    "\n",
    "    return '\\n'.join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stockfish 14 by the Stockfish developers (see AUTHORS file)\n",
      "readyok\n",
      "info string NNUE evaluation using nn-3475407dc199.nnue enabled\n",
      "\n",
      "Final evaluation: none (in check)\n",
      "========================\n",
      "info string NNUE evaluation using nn-3475407dc199.nnue enabled\n",
      "\n",
      "Contributing terms for the classical eval:\n",
      "+------------+-------------+-------------+-------------+\n",
      "|    Term    |    White    |    Black    |    Total    |\n",
      "|            |   MG    EG  |   MG    EG  |   MG    EG  |\n",
      "+------------+-------------+-------------+-------------+\n",
      "|   Material |  ----  ---- |  ----  ---- |  0.80  0.49 |\n",
      "|  Imbalance |  ----  ---- |  ----  ---- |  0.00  0.00 |\n",
      "|      Pawns |  0.29 -0.06 |  0.38 -0.05 | -0.09 -0.01 |\n",
      "|    Knights | -0.31 -0.35 | -0.11 -0.20 | -0.20 -0.14 |\n",
      "|    Bishops | -0.13 -0.45 | -0.09 -0.79 | -0.04  0.35 |\n",
      "|      Rooks | -0.26 -0.06 | -0.53 -0.12 |  0.26  0.06 |\n",
      "|     Queens |  0.00  0.00 |  0.00  0.00 |  0.00  0.00 |\n",
      "|   Mobility |  0.83  1.05 |  0.69  0.90 |  0.14  0.14 |\n",
      "|King safety | -0.71 -0.40 | -3.30 -0.51 |  2.60  0.11 |\n",
      "|    Threats |  1.41  1.99 |  1.21  1.00 |  0.21  0.99 |\n",
      "|     Passed |  0.00  0.00 |  0.00  0.00 |  0.00  0.00 |\n",
      "|      Space |  0.36  0.00 |  0.36  0.00 |  0.00  0.00 |\n",
      "|   Winnable |  ----  ---- |  ----  ---- |  0.00  0.00 |\n",
      "+------------+-------------+-------------+-------------+\n",
      "|      Total |  ----  ---- |  ----  ---- |  3.67  1.99 |\n",
      "+------------+-------------+-------------+-------------+\n",
      "\n",
      "NNUE derived piece values:\n",
      "+-------+-------+-------+-------+-------+-------+-------+-------+\n",
      "|   r   |       |   b   |   k   |       |   b   |   n   |   r   |\n",
      "| -4.08 |       | -2.90 |       |       | -2.57 | -1.75 | -4.27 |\n",
      "+-------+-------+-------+-------+-------+-------+-------+-------+\n",
      "|       |   p   |   p   |       |       |   p   |   p   |   p   |\n",
      "|       | -1.29 | -1.62 |       |       | -1.36 | -1.44 | +0.08 |\n",
      "+-------+-------+-------+-------+-------+-------+-------+-------+\n",
      "|   p   |       |   n   |       |       |   q   |       |       |\n",
      "| +0.05 |       | -2.67 |       |       | -9.28 |       |       |\n",
      "+-------+-------+-------+-------+-------+-------+-------+-------+\n",
      "|       |       |       |   N   |       |       |   N   |       |\n",
      "|       |       |       | +3.58 |       |       | +3.51 |       |\n",
      "+-------+-------+-------+-------+-------+-------+-------+-------+\n",
      "|       |       |       |       |       |       |   B   |       |\n",
      "|       |       |       |       |       |       | +2.94 |       |\n",
      "+-------+-------+-------+-------+-------+-------+-------+-------+\n",
      "|       |       |       |       |       |       |       |       |\n",
      "|       |       |       |       |       |       |       |       |\n",
      "+-------+-------+-------+-------+-------+-------+-------+-------+\n",
      "|   P   |   P   |   P   |       |       |   P   |   P   |   P   |\n",
      "| +0.25 | +1.10 | +0.86 |       |       | +0.97 | +1.71 | +0.44 |\n",
      "+-------+-------+-------+-------+-------+-------+-------+-------+\n",
      "|   R   |       |   B   |   Q   |   K   |       |       |   R   |\n",
      "| +3.15 |       | +2.80 | +11.2 |       |       |       | +2.93 |\n",
      "+-------+-------+-------+-------+-------+-------+-------+-------+\n",
      "\n",
      "NNUE network contributions (Black to move)\n",
      "+------------+------------+------------+------------+\n",
      "|   Bucket   |  Material  | Positional |   Total    |\n",
      "|            |   (PSQT)   |  (Layers)  |            |\n",
      "+------------+------------+------------+------------+\n",
      "|  0         |  -  0.54   |  -  1.58   |  -  2.13   |\n",
      "|  1         |  -  0.23   |  -  0.57   |  -  0.80   |\n",
      "|  2         |  -  0.60   |  -  1.25   |  -  1.86   |\n",
      "|  3         |  -  0.97   |  -  1.50   |  -  2.47   |\n",
      "|  4         |  -  1.01   |  -  2.29   |  -  3.31   |\n",
      "|  5         |  -  0.82   |  -  2.28   |  -  3.11   |\n",
      "|  6         |  -  0.69   |  -  2.32   |  -  3.01   | <-- this bucket is used\n",
      "|  7         |  -  0.62   |  -  2.46   |  -  3.08   |\n",
      "+------------+------------+------------+------------+\n",
      "\n",
      "\n",
      "Classical evaluation   +3.62 (white side)\n",
      "NNUE evaluation        +3.02 (white side)\n",
      "Final evaluation       +5.48 (white side) [with scaled NNUE, hybrid, ...]\n"
     ]
    }
   ],
   "source": [
    "''' Testing '''\n",
    "with start_engine_process() as p:\n",
    "    # In-check position shouldn't give static eval\n",
    "    print(analyze_static(p, 'r3r3/pppkb1pp/8/n2nN3/8/8/PPPP1PPP/RNB1K2R b KQ - 2 12'))\n",
    "\n",
    "    print('========================')\n",
    "\n",
    "    # Other positions should give static eval\n",
    "    output = analyze_static(p, 'r1bk1bnr/1pp2ppp/p1n2q2/3N2N1/6B1/8/PPP2PPP/R1BQK2R b KQ - 0 12')\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Feature Generation from Game Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def vectorize_contributing_terms(static_analysis_output: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Return an array with shape (68,) of numbers from the \"Contributing terms...\" table\n",
    "    given by the Stockfish static analysis.\n",
    "    \"\"\"\n",
    "    # Regex tester\n",
    "    # https://regex101.com/r/OWV1ee/4\n",
    "    return np.array([float(i)\n",
    "                     for tup in re.findall('([-]?(?:[0-9]*[.])?[0-9]+) +([-]?(?:[0-9]*[.])?[0-9]+)', static_analysis_output)\n",
    "                     for i in tup])\n",
    "\n",
    "_BOARD = chess.Board()\n",
    "def vectorize_board_state(*,\n",
    "                          board: chess.Board = None,\n",
    "                          fen: str = None,\n",
    "                          packbits: bool = False) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Take either a Board or a FEN and return a 3d vector of the board state with shape (8, 8, 12)\n",
    "    if packbits is False, else (8, 8, 2). Each vector or int in the (8, 8) outer vectors returned\n",
    "    is a one-hot encoding of the piece type at that square.\n",
    "\n",
    "    Method taken from here: https://chess.stackexchange.com/a/34399/19286\n",
    "\n",
    "    One-hot encoding examples:\n",
    "        format: pnbrqkPNBRQK\n",
    "                ------------\n",
    "                000010000000 = black queen\n",
    "                000000010000 = white knight\n",
    "\n",
    "    :param board: Board object (preferred if available)\n",
    "    :param fen: String to make a new Board object\n",
    "    :param packbits: If True, each square's one-hot encoding is packed into the\n",
    "            binary representation of two np.bytes, instead of a vector of 0/1 ints.\n",
    "            See https://numpy.org/doc/stable/reference/generated/numpy.packbits.html\n",
    "    \"\"\"\n",
    "\n",
    "    # Provide Board or FEN, not both\n",
    "    assert (board, fen).count(None) == 1, f'error: vectorize_board_state() takes either a Board or a FEN str, not both'\n",
    "    if board is None:\n",
    "        _BOARD.set_fen(fen)\n",
    "        board = _BOARD\n",
    "\n",
    "    # Bitboards of all white and black pieces\n",
    "    black, white = board.occupied_co\n",
    "\n",
    "    # Bitboards each piece type by color\n",
    "    bbs = np.array([\n",
    "        black & board.pawns,\n",
    "        black & board.knights,\n",
    "        black & board.bishops,\n",
    "        black & board.rooks,\n",
    "        black & board.queens,\n",
    "        black & board.kings,\n",
    "        white & board.pawns,\n",
    "        white & board.knights,\n",
    "        white & board.bishops,\n",
    "        white & board.rooks,\n",
    "        white & board.queens,\n",
    "        white & board.kings,\n",
    "    ])\n",
    "\n",
    "    result = np.array([np.array([np.array([int(ch) for ch in row]).astype(np.int16, copy=False)\n",
    "                             for row in wrap(f'{str(bin(int(bb)))[2:]:0>64}', 8)])\n",
    "                   for bb in bbs]).swapaxes(0, 1).swapaxes(1, 2)\n",
    "    assert result.shape == (8, 8, 12)\n",
    "\n",
    "    if packbits:\n",
    "        result = np.packbits(result, axis=-1)\n",
    "        assert result.shape == (8, 8, 2)\n",
    "\n",
    "    return result\n",
    "\n",
    "def unpack_vectorized_board_state(packed_vectorized_board_state: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Takes a vectorized board state array with packed bits (the result of calling\n",
    "    vectorize_board_state(..., packbits=True)) and unpack the bits back into a one-hot\n",
    "    encoded vector (the result of vectorize_board_state(..., packbits=False))\n",
    "    \"\"\"\n",
    "    assert packed_vectorized_board_state.shape == (8, 8, 2)\n",
    "    return np.unpackbits(packed_vectorized_board_state, axis=-1)[:,:,:12].astype(np.int16)\n",
    "\n",
    "# Stockfish's starting eval, the eval before any moves are made\n",
    "START_POSITION_EVAL = +0.3\n",
    "# Manually store number of features expected to be\n",
    "# returned to make sure everything works properly\n",
    "# CURRENT_NUM_FEATURES = 841\n",
    "CURRENT_NUM_FEATURES = 74\n",
    "def vectorize_game_moves(proc: subprocess.Popen, game: chess.pgn.Game, max_moves: int = None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Return a (max(#plies, max_moves if not None))x(CURRENT_NUM_FEATURES + 1) array. If max_moves is set,\n",
    "    a random set of max_moves moves will be chosen from the game to process and return, however\n",
    "    occasionally the number of rows in the returned array will be < max_moves if either side is\n",
    "    in check during a ply that was randomly selected to be included in the output (static eval\n",
    "    doesn't work for in-check positions).\n",
    "\n",
    "    For each ply (half-move) in the game, the following features are extracted:\n",
    "        Game-specific features:\n",
    "        - Player ELO rating\n",
    "        - Opponent ELO rating\n",
    "        - Rating gap (Opponent ELO - Player ELO)\n",
    "        - Clock starting time (seconds)\n",
    "        - Clock increment (seconds)\n",
    "        Move-specific features:\n",
    "        - Ply (# half-moves into the game)\n",
    "        - Static eval features:\n",
    "            - 68 features: floats from the \"Contributing terms ...\" table\n",
    "            - (TODO) 64 features: floats from the \"NNUE-derived piece values\" table\n",
    "                - Not sure how to deal with squares without pieces, filling with 0s might not make sense\n",
    "        - Board state:\n",
    "            - 768 features: 64 squares * 12 bits for one-hot encoded piece types\n",
    "\n",
    "    The final column is the target column holding the centipawn loss (CPL) of the player's move in the position.\n",
    "    \"\"\"\n",
    "\n",
    "    # Data to be returned\n",
    "    # Storing as builtin list type is slightly faster than np.array\n",
    "    data = []\n",
    "\n",
    "    # Set up board and Game's move nodes\n",
    "    board = game.board()\n",
    "    mainline_nodes: List[chess.pgn.ChildNode] = list(game.mainline())\n",
    "    if len(mainline_nodes) < 2:\n",
    "        raise ValueError(f'error: fewer than two moves in the game\\'s mainline. '\n",
    "                         f'Is game from a ...___cleaned.pgn? game: {game}')\n",
    "\n",
    "    # Get indices of plies to use. If max_moves given, use only a subset of all game moves\n",
    "    plies_to_use = set(range(len(mainline_nodes)))\n",
    "    if max_moves is not None:\n",
    "        if not isinstance(max_moves, int) or max_moves <= 0:\n",
    "            raise ValueError('error: max_moves should be an int > 0')\n",
    "        if max_moves < len(plies_to_use):\n",
    "            # Bulitin random.sample is faster than the np options\n",
    "            plies_to_use = set(random.sample(plies_to_use, max_moves))\n",
    "    if not plies_to_use:\n",
    "        print(f'warning: plies_to_use is empty. Is game from a ...cleaned.pgn? game: {game}')\n",
    "\n",
    "    ''' Add row to `data` for each move '''\n",
    "    # Set game-specific features (constants while iterating over moves in the game)\n",
    "    h = game.headers\n",
    "    try:\n",
    "        clock_start, clock_inc = parse_time_control(h['TimeControl'])\n",
    "    except ValueError as e:\n",
    "        print(f'error: ValueError parsing time control. Is game from a ...___cleaned.pgn? '\n",
    "              f'game: {game}')\n",
    "        raise e\n",
    "    try:\n",
    "        white_elo = int(h['WhiteElo'])\n",
    "        black_elo = int(h['BlackElo'])\n",
    "    except KeyError as e:\n",
    "        # No player ratings in the game headers, should be using cleaned data\n",
    "        print(f'error: KeyError for \"WhiteElo\" or \"BlackElo\" in game.headers. '\n",
    "              f'Is game from a ...___cleaned.pgn? game.headers: {game.headers}')\n",
    "        raise e\n",
    "    game_features_white = np.array([h['WhiteElo'], h['BlackElo'], (black_elo-white_elo), clock_start, clock_inc])\n",
    "    game_features_black = np.array([h['BlackElo'], h['WhiteElo'], (white_elo-black_elo), clock_start, clock_inc])\n",
    "\n",
    "    # Add row of features for all selected moves in the Game\n",
    "    last_score: float = START_POSITION_EVAL\n",
    "    for ply, node in enumerate(mainline_nodes):\n",
    "        # Break condition: last ply's node may not have \"%eval\"\n",
    "        # in the comment (if its move gives checkmate/stalemate)\n",
    "        try:\n",
    "            score = get_score_from_comment(node.comment)\n",
    "        except ValueError as e:\n",
    "            # For this dataset, %eval comments stop at ply 200 (0-indexed, ex. white's move 101)\n",
    "            if ply == 200:\n",
    "                break\n",
    "\n",
    "            # Can't get cpl if this move has no %eval\n",
    "            # If there's no %eval because it's the last ply, that's fine\n",
    "            if ply == len(mainline_nodes)-1:\n",
    "                board.push(node.move)\n",
    "                assert board.is_game_over(claim_draw=True)\n",
    "                break\n",
    "\n",
    "            # Otherwise something weird is going on\n",
    "            print(f'error: ValueError getting score from comment: {e}')\n",
    "            print(f'\\tgame link: {game.headers[\"Site\"]}')\n",
    "            print(f'\\tcomment: {node.comment}')\n",
    "            print(f'\\tply: {ply}')\n",
    "            print(f'\\ttotal # plies: {len(mainline_nodes)}')\n",
    "            print(f'\\tfen: {board.fen()}')\n",
    "            print(f'\\tmove: {board.san(node.move)}')\n",
    "            raise e\n",
    "\n",
    "        # Continue if in check (can't get static eval in check)\n",
    "        # and skip move if this ply was not chosen to be used\n",
    "        if board.is_check() or ply not in plies_to_use:\n",
    "            last_score = score\n",
    "            try:\n",
    "                board.push(node.move)\n",
    "                continue\n",
    "            except AssertionError as e:\n",
    "                # Something weird going on, python-chess thinks move is illegal\n",
    "                print(f'warning: AssertionError while pushing move: {e}')\n",
    "                print(f'\\tmove: {node.move}')\n",
    "                print(f'\\tboard.fen(): {board.fen()}')\n",
    "                print(f'\\tply: {ply}')\n",
    "                print(f'\\tplies_to_use: {plies_to_use}')\n",
    "                break\n",
    "\n",
    "        # Get game-specific features\n",
    "        game_features = (game_features_black, game_features_white)[board.turn == chess.WHITE]\n",
    "\n",
    "        # Set move-specific features\n",
    "        static_eval_features = vectorize_contributing_terms(analyze_static(proc, board.fen()))\n",
    "        # board_state_features = vectorize_board_state(board, flatten=True)\n",
    "        board_state_features = [board.fen()]\n",
    "\n",
    "        # Set centipawn loss (CPL)\n",
    "        cpl = get_cpl(last_score, score, board.turn)\n",
    "\n",
    "        # # CPL should rarely be < 0 (player makes a move better than top computer line)\n",
    "        # if cpl < 0:\n",
    "        #     print('test: cpl less than 0')\n",
    "        #     print(f'\\tmove made by {chess.COLOR_NAMES[board.turn]}')\n",
    "        #     print(f'\\tlast_score: {last_score}')\n",
    "        #     print(f'\\tscore: {score}')\n",
    "        #     print(f'\\tcpl: {cpl}')\n",
    "        #     print(f'\\tboard.fen(): {board.fen()}')\n",
    "        #     print(f'\\tmove: {board.san(node.move)}')\n",
    "\n",
    "        # Create row\n",
    "        all_features = np.array([*game_features, *static_eval_features, *board_state_features, cpl])\n",
    "\n",
    "        # # Validate shape\n",
    "        assert all_features.shape == (CURRENT_NUM_FEATURES+1,), f'error: all_features wasn\\'t properly formed. all_features: {all_features}'\n",
    "\n",
    "        # Add the row\n",
    "        data.append(all_features)\n",
    "\n",
    "        # Play next move\n",
    "        board.push(node.move)\n",
    "        last_score = score\n",
    "\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "  [0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "  [0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "  [0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "  [0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 1 0 0 0 0 0 0 0 0]]\n",
      "\n",
      " [[1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [1 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 1 0 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "  [0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "  [0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "  [0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "  [0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 1 0 0]]]\n",
      "\n",
      "\n",
      "================\n",
      "\n",
      "\n",
      "[[[ 16   0]\n",
      "  [ 64   0]\n",
      "  [ 32   0]\n",
      "  [  4   0]\n",
      "  [  8   0]\n",
      "  [ 32   0]\n",
      "  [ 64   0]\n",
      "  [ 16   0]]\n",
      "\n",
      " [[128   0]\n",
      "  [128   0]\n",
      "  [128   0]\n",
      "  [128   0]\n",
      "  [128   0]\n",
      "  [128   0]\n",
      "  [128   0]\n",
      "  [128   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  2   0]\n",
      "  [  2   0]\n",
      "  [  2   0]\n",
      "  [  2   0]\n",
      "  [  2   0]\n",
      "  [  2   0]\n",
      "  [  2   0]\n",
      "  [  2   0]]\n",
      "\n",
      " [[  0  64]\n",
      "  [  1   0]\n",
      "  [  0 128]\n",
      "  [  0  16]\n",
      "  [  0  32]\n",
      "  [  0 128]\n",
      "  [  1   0]\n",
      "  [  0  64]]]\n"
     ]
    }
   ],
   "source": [
    "''' Board state vectorization '''\n",
    "print(vectorize_board_state(board=chess.Board()))\n",
    "print('\\n\\n================\\n\\n')\n",
    "print(vectorize_board_state(board=chess.Board(), packbits=True))\n",
    "# print('\\n\\n================\\n\\n')\n",
    "# print(vectorize_board_state(fen=chess.STARTING_FEN))\n",
    "\n",
    "# How to unpack bits from the result if packbits=True set\n",
    "assert np.all(np.equal(\n",
    "    unpack_vectorized_board_state(vectorize_board_state(board=chess.Board(), packbits=True)),\n",
    "    vectorize_board_state(board=chess.Board(), packbits=False))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "''' Get game data for the two test PGNs '''\n",
    "with start_engine_process() as p:\n",
    "    NUM_MOVES = None\n",
    "\n",
    "    carlson_game = chess.pgn.read_game(io.StringIO(carlson_pgn))\n",
    "    jackson_game = chess.pgn.read_game(io.StringIO(jackson_pgn))\n",
    "\n",
    "    carlson_game_data = vectorize_game_moves(p, carlson_game, max_moves=NUM_MOVES)\n",
    "    jackson_game_data = vectorize_game_moves(p, jackson_game, max_moves=NUM_MOVES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([['2998', '3141', '143', ..., '0.0',\n        'rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1', '6'],\n       ['3141', '2998', '-143', ..., '0.88',\n        'rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR b KQkq - 0 1',\n        '20'],\n       ['2998', '3141', '143', ..., '0.51',\n        'r1bqkbnr/pppppppp/2n5/8/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 1 2',\n        '20'],\n       ...,\n       ['3141', '2998', '-143', ..., '1.43',\n        '8/2k2b2/1p1p2p1/pB1p1p1p/P2P1P1P/1PP3P1/2K5/8 b - - 19 42',\n        '-17'],\n       ['2998', '3141', '143', ..., '1.76',\n        '3k4/5b2/1p1p2p1/pB1p1p1p/P2P1P1P/1PP3P1/2K5/8 w - - 20 43',\n        '-16'],\n       ['3141', '2998', '-143', ..., '1.69',\n        '3k4/5b2/1p1p2p1/pB1p1p1p/P2P1P1P/1PP3P1/3K4/8 b - - 21 43',\n        '-16']], dtype='<U69')"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data for Magnus Carlson's game\n",
    "# Last column (CPL) should be around 0 (+/- 30) because both players played accurately\n",
    "# Occasionally CPL can be <0 since both players are so high rated they found moves\n",
    "# that the engine underestimated or didn't consider at a low depth\n",
    "carlson_game_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "array([['1930', '1912', '-18', ..., '0.0',\n        'rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1', '6'],\n       ['1912', '1930', '18', ..., '0.88',\n        'rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR b KQkq - 0 1',\n        '58'],\n       ['1930', '1912', '-18', ..., '0.24',\n        'rnbqkbnr/ppp1pppp/8/3p4/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 0 2',\n        '46'],\n       ...,\n       ['1912', '1930', '18', ..., '2.81',\n        'r1bqkbnr/1pp1p1p1/p1n1Np2/2N4p/7P/3B1Q2/PPPP1PP1/R1B2RK1 b kq - 3 13',\n        '2'],\n       ['1930', '1912', '-18', ..., '-3.9',\n        'r2qkbnr/1pp1p1p1/p1n1bp2/2N4p/7P/3B1Q2/PPPP1PP1/R1B2RK1 w kq - 0 14',\n        '-25'],\n       ['1912', '1930', '18', ..., '2.62',\n        'r2qkbnr/1pp1p1p1/p1n1Np2/7p/7P/3B1Q2/PPPP1PP1/R1B2RK1 b kq - 0 14',\n        '9121']], dtype='<U68')"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data for Jackson's game\n",
    "# Last column (CPL) should be higher, fluctuate more, and rarely/never be <0\n",
    "jackson_game_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Make a CSV Dataset\n",
    "\n",
    "Above are functions to export data points (training examples) for a single game. This reads from multiple games to generate a CSV that combines all their data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def export_to_csv(csv_filename: str, data: np.array, reset_file: bool = False) -> None:\n",
    "    \"\"\"\n",
    "    Export a given 2d numpy array to a csv file. If reset_file is True,\n",
    "    open in write mode, else open in append mode.\n",
    "    \"\"\"\n",
    "    open_mode = ('a', 'w')[reset_file]\n",
    "    while True:\n",
    "        try:\n",
    "            with open(csv_filename, open_mode) as f:\n",
    "                np.savetxt(f, data, fmt='%s', delimiter=',')\n",
    "            break\n",
    "        except PermissionError:\n",
    "            input(f'error: PermissionError while writing file. Please close '\n",
    "                  f'{csv_filename} and press enter: ')\n",
    "\n",
    "PREPARE_DATA_WRITE_BATCH_SIZE = 900\n",
    "def create_dataset(pgn_filename: str,\n",
    "                 output_csv_filename: str = None,\n",
    "                 max_datapoints: int = None,\n",
    "                 max_datapoints_per_game: int = None) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Process games using vectorize_game_moves() and export results to output_csv_filename in batches of\n",
    "    PREPARE_DATA_WRITE_BATCH_SIZE.\n",
    "\n",
    "    :param pgn_filename: Input filename. Should be a \"...___cleaned.pgn\" if one has been generated.\n",
    "    :param output_csv_filename: CSV where data will be stored. If set to None, a descriptive filename\n",
    "            will be generated.\n",
    "    :param max_datapoints: If set, limits the number of points (rows) that will be included in the output file\n",
    "    :param max_datapoints_per_game: If set, chooses a random subset of each game's moves to process. If None,\n",
    "            all moves in each game will be processed until the file is exhausted or max_datapoints rows have\n",
    "            been collected.\n",
    "    \"\"\"\n",
    "\n",
    "    # Input file must be PGN\n",
    "    assert os.path.splitext(pgn_filename)[1].lower() == '.pgn'\n",
    "\n",
    "    # Set filename if it wasn't given\n",
    "    if output_csv_filename is None:\n",
    "        # Set the new name to be the input filename with a descriptive name appended\n",
    "        name, _ = os.path.splitext(pgn_filename)\n",
    "        middle_part = '___data'\n",
    "        if max_datapoints_per_game is not None:\n",
    "            middle_part += f'_max_{max_datapoints_per_game}_moves_per_game'\n",
    "        else:\n",
    "            middle_part += '_no_max_moves_per_game'\n",
    "        output_csv_filename = name + middle_part + '.csv'\n",
    "    else:\n",
    "        assert os.path.splitext(output_csv_filename)[1].lower() == '.csv'\n",
    "\n",
    "    # Warn if overwriting\n",
    "    if os.path.exists(output_csv_filename):\n",
    "        if not validate_yn(f'warning: {output_csv_filename} will be overwritten even though its size is '\n",
    "                           f'{os.path.getsize(output_csv_filename) / 1e6:.2f}Mb. Continue? (y/n)'):\n",
    "            print('Aborting.')\n",
    "            return output_csv_filename\n",
    "\n",
    "    # Vectorize moves in games and write output file\n",
    "    start_time = timeit.default_timer()\n",
    "    empty_data = np.empty((0, CURRENT_NUM_FEATURES + 1))\n",
    "    data = empty_data.copy()\n",
    "    with start_engine_process() as proc:\n",
    "        num_games = 0               # Incremented each game\n",
    "        total_num_datapoints = 0    # Incremented each move\n",
    "        num_datapoints = 0          # Incremented each move, reset when data is appended to csv\n",
    "        num_discarded = 0\n",
    "        output_file_started = False\n",
    "\n",
    "        # tqdm just shows a progress bar\n",
    "        # https://github.com/tqdm/tqdm\n",
    "        for game in tqdm(generate_games(pgn_filename)):\n",
    "            # Get new data\n",
    "            new_data = vectorize_game_moves(proc, game, max_moves=max_datapoints_per_game)\n",
    "            data = np.concatenate((data, new_data), axis=0)\n",
    "\n",
    "            # Update counting vars\n",
    "            num_games += 1\n",
    "            num_datapoints += new_data.shape[0]\n",
    "            total_num_datapoints += new_data.shape[0]\n",
    "\n",
    "            # Append to CSV and reset `data` after it has more than PREPARE_DATA_WRITE_BATCH_SIZE rows (to save RAM)\n",
    "            if max_datapoints is not None and total_num_datapoints >= max_datapoints:\n",
    "                # Write only the number of rows that would give the file max_datapoints rows\n",
    "                num_discarded = total_num_datapoints - max_datapoints\n",
    "                data_to_write = data[:-num_discarded,:]\n",
    "\n",
    "                print(f'{datetime.datetime.now()}: Writing final {data_to_write.shape[0]} rows '\n",
    "                      f'(total {max_datapoints})...', end='')\n",
    "                export_to_csv(csv_filename=output_csv_filename, data=data_to_write, reset_file=not output_file_started)\n",
    "                print('done.')\n",
    "\n",
    "                break\n",
    "            elif num_datapoints >= PREPARE_DATA_WRITE_BATCH_SIZE:\n",
    "                # Write all rows\n",
    "                print(f'{datetime.datetime.now()}: Writing {num_datapoints} rows '\n",
    "                      f'(total {total_num_datapoints})...', end='')\n",
    "                export_to_csv(csv_filename=output_csv_filename, data=data, reset_file=not output_file_started)\n",
    "                print('done.')\n",
    "\n",
    "                # Reset data array to free up memory\n",
    "                data = empty_data.copy()\n",
    "                num_datapoints = 0\n",
    "                output_file_started = True\n",
    "\n",
    "    print('Results:')\n",
    "    print(f'\\t{min(total_num_datapoints, max_datapoints) if max_datapoints is not None else total_num_datapoints:,} '\n",
    "          f'data points written to \"{output_csv_filename}\" '\n",
    "          f'({os.path.getsize(output_csv_filename) / 1e6:.2f}Mb)')\n",
    "    print(f'\\t{total_num_datapoints:,} plies vectorized ({num_discarded} discarded)')\n",
    "    print(f'\\t{num_games:,} games parsed '\n",
    "          f'(<={max_datapoints_per_game if max_datapoints_per_game is not None else 200} plies vectorized per game)')\n",
    "    print(f'\\t{timeit.default_timer() - start_time:.2f}s elapsed')\n",
    "\n",
    "    return output_csv_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aborting.\n"
     ]
    }
   ],
   "source": [
    "# This filename can also be set above if export_valid_games() is called\n",
    "# noinspection PyRedeclaration\n",
    "CLEANED_PGN_FILENAME = 'data/lichess_db_standard_rated_2015-09___cleaned.pgn'\n",
    "data_filename = create_dataset(CLEANED_PGN_FILENAME,\n",
    "                               max_datapoints=1_000_000,\n",
    "                               max_datapoints_per_game=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Load Random Sample of CSV Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_moves_data(csv_filename: str,\n",
    "                    sample_size: int = 10_000,\n",
    "                    max_population: Optional[int] = 1_000_000,\n",
    "                    include_numeric: bool = True,\n",
    "                    include_fens: bool = True,\n",
    "                    vectorize_fens: bool = False,\n",
    "                    include_target: bool = True,\n",
    "                    split_X_y: bool = False,\n",
    "                    split_numeric_fens: bool = False) \\\n",
    "        -> Union[np.ndarray, Tuple[np.ndarray, np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Load a random sample of all data from the given CSV into a numpy array. There are a lot of\n",
    "    configurable options below to choose from that will suit a range of ML applications.\n",
    "\n",
    "    :param csv_filename: Input file where data will be read from\n",
    "    :param sample_size: Number of rows to be returned. If csv_filename doesn't have sample_size rows,\n",
    "            a warning is printed and all rows are returned in order in the specified format.\n",
    "    :param max_population: Maximum number of rows that will be read from the file to potentially be\n",
    "            chosen in the random sample. Ex. if csv_filename has 10M rows but max_population is 100K,\n",
    "            only the first 100K rows of the file will be iterated over.\n",
    "    :param include_numeric: If True, include the numeric feature columns in the output (ex. game data,\n",
    "            static eval features, etc.), otherwise remove them.\n",
    "    :param include_fens: If True, include the FEN column in the output. In this case, if\n",
    "            split_numeric_fens is also False, all feature columns (even numeric ones) will have type\n",
    "            np.str_, not useful for machine learning. To avoid this, either set include_numeric=False\n",
    "            or split_numeric_fens=True. Then only the FEN array will have type np.str_, and other types\n",
    "            will be set to np.float32 automatically. If False, remove the FEN column and automatically\n",
    "            set all other numeric dtypes to np.float32.\n",
    "    :param vectorize_fens: If True, include_numeric must be False and split_X_y must be True so that\n",
    "            the FEN column in the output is isolated in a single np.array. This is to preserve dtypes of\n",
    "            the array that is output by vectorize_board_state(). If True, calls\n",
    "            vectorize_board_state(packbits=False) for each FEN in the FEN column to produce an output\n",
    "            array with shape (sample_size, 8, 8, 12). Otherwise, the FEN column are returned as strings\n",
    "            (specifically as np.str_ types).\n",
    "    :param include_target: If True, include the target column in the output, otherwise remove it.\n",
    "    :param split_X_y: If True, return an array `X` with the features and a column vector `y` with the\n",
    "            targets, otherwise return a single array with the included data\n",
    "    :param split_numeric_fens: If True, split_X_y must be True. Return 3 arrays `X` with the numeric\n",
    "            features, `fens` with the FENs, and `y` with the targets.\n",
    "    \"\"\"\n",
    "\n",
    "    ''' Validate inputs '''\n",
    "    if max_population is not None:\n",
    "        if sample_size > max_population:\n",
    "            raise ValueError('error: sample_size should be <= max_population')\n",
    "\n",
    "    if not any((include_numeric, include_fens, include_target)):\n",
    "        raise ValueError('error: no columns selected to be returned (one of '\n",
    "                         'include_numeric, include_fens, include_target must be True)')\n",
    "\n",
    "    if split_numeric_fens and not all((include_numeric, include_fens)):\n",
    "        raise ValueError('error: if split_numeric_fens=True, include_numeric and include_fens must be True')\n",
    "\n",
    "    if (not any((include_numeric, include_fens)) or not include_target) and split_X_y:\n",
    "        raise ValueError('error: if split_X_y=True, one of (include_numeric, include_fens) must be True '\n",
    "                         'and include_target must be True')\n",
    "\n",
    "    if split_numeric_fens and not split_X_y:\n",
    "        raise ValueError('error: if split_numeric_fens=True, split_X_y must be True')\n",
    "\n",
    "    if vectorize_fens and not split_numeric_fens:\n",
    "        if include_numeric or not include_fens or not split_X_y:\n",
    "            raise ValueError('error: if vectorize_fens=True, make sure the following arguments are set:\\n'\n",
    "                             '\\t- include_fens=True\\n'\n",
    "                             '\\t- include_numeric=False\\n'\n",
    "                             '\\t- split_X_y=True\\n'\n",
    "                             'to preserve the np.array dtype output by vectorize_board_state(). Otherwise '\n",
    "                             'all types will be cast to np.str_.')\n",
    "\n",
    "    ''' Take a random sample of CSV rows as strings '''\n",
    "    # This method is from Answer #3 here:\n",
    "    # https://www.py4u.net/discuss/21578\n",
    "    buffer = []\n",
    "    with open(csv_filename, 'r') as f:\n",
    "        for line_num, line in tqdm(enumerate(f)):\n",
    "            if max_population is not None and line_num == max_population:\n",
    "                break\n",
    "\n",
    "            line_num += 1\n",
    "            if line_num <= sample_size:\n",
    "                # Add first sample_size elements\n",
    "                buffer.append(line.strip())\n",
    "            elif random.random() < sample_size/line_num:\n",
    "                # Eject a random element from buffer\n",
    "                idx = random.randint(0, sample_size-1)\n",
    "                buffer[idx] = line.strip()\n",
    "    print('Converting CSV rows to np.arrays...', end='')\n",
    "    data = np.array(list(csv.reader(buffer)))\n",
    "    numeric, fens, target = data[:,:-2].astype(np.float32), data[:,-2], data[:,-1].astype(np.float32)\n",
    "    print('done.')\n",
    "\n",
    "    if sample_size > data.shape[0]:\n",
    "        print(f'warning: There were only {data.shape[0]:,} < sample_size={sample_size:,} rows '\n",
    "              f'in {csv_filename}. All {data.shape[0]:,} rows were returned.')\n",
    "\n",
    "    ''' Delete unwanted columns '''\n",
    "    if not include_numeric:\n",
    "        numeric = np.delete(numeric, slice(None), axis=-1)\n",
    "\n",
    "    if not include_fens:\n",
    "        # Safe to convert types now\n",
    "        fens = np.delete(fens, slice(None), axis=-1)\n",
    "    elif vectorize_fens:\n",
    "        # Safe to vectorize now because error is raised above if include_numeric=True\n",
    "        print('Vectorizing FENs...', end='')\n",
    "        fens = np.array([vectorize_board_state(fen=fen) for fen in fens.ravel()])\n",
    "        print('done.')\n",
    "    elif include_numeric and not split_numeric_fens:\n",
    "        print(f'warning: numeric dtypes ({\"EX\" if split_X_y else \"IN\"}CLUDING target) are still np.str_ '\n",
    "              '(numpy doesn\\'t do well with multi-type arrays). They will need to be converted to np.float32 manually '\n",
    "              'unless load_moves_data() is called with include_fens=False, or with split_numeric_fens=True to place the '\n",
    "              'FENs into a new column - in either case all numeric data will be converted to np.float32 dtypes '\n",
    "              'automatically.')\n",
    "\n",
    "    if not include_target:\n",
    "        target = np.delete(target, slice(None), axis=-1)\n",
    "\n",
    "    ''' Set & return appropriate result '''\n",
    "    # A mess of logic but it works\n",
    "    if split_X_y:\n",
    "        if split_numeric_fens:\n",
    "            result = numeric, fens, target\n",
    "        else:\n",
    "            if include_numeric and include_fens:\n",
    "                result = np.concatenate((numeric, fens.reshape((-1, 1))), axis=-1), target\n",
    "            elif include_numeric:\n",
    "                result = numeric, target\n",
    "            else:\n",
    "                assert include_fens  # Only other path\n",
    "                result = fens, target\n",
    "    else:\n",
    "        if include_numeric and include_fens and include_target:\n",
    "            result = np.concatenate((numeric, fens.reshape((-1, 1)), target.reshape((-1, 1))), axis=-1)\n",
    "        elif include_numeric and include_fens:\n",
    "            result = np.concatenate((numeric, fens.reshape((-1, 1))), axis=-1)\n",
    "        elif include_numeric and include_target:\n",
    "            result = np.concatenate((numeric, target.reshape((-1, 1))), axis=-1)\n",
    "        elif include_fens and include_target:\n",
    "            result = np.concatenate((fens.reshape((-1, 1)), target.reshape((-1, 1))), axis=-1)\n",
    "        elif include_numeric:\n",
    "            result = numeric\n",
    "        elif include_fens:\n",
    "            result = fens\n",
    "        else:\n",
    "            assert include_target  # Only other path\n",
    "            result = target\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Testing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting CSV rows to np.arrays...done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([ 3.100e+01,  1.470e+02,  9.000e+00, -5.720e+02,  1.200e+01,\n        1.090e+02,  1.620e+02,  4.700e+01,  1.800e+01, -3.000e+00,\n        8.000e+00,  1.000e+01,  3.792e+03, -1.500e+01,  2.060e+02,\n        1.000e+00,  9.114e+03,  3.510e+02, -4.000e+00, -1.000e+00,\n        1.000e+00,  6.500e+01,  6.000e+00, -2.000e+00, -3.000e+00,\n        4.000e+00, -5.000e+00,  2.200e+01,  2.800e+01,  2.160e+02,\n        2.000e+01,  2.100e+01,  2.100e+01,  2.000e+01,  6.000e+00,\n        1.000e+01,  3.900e+01,  7.000e+01, -1.000e+00,  8.400e+01,\n        8.000e+00,  7.700e+01,  3.700e+01,  2.500e+01,  4.000e+00,\n        1.810e+02,  0.000e+00,  0.000e+00,  2.400e+01,  6.010e+02,\n        2.900e+01, -1.000e+00,  9.800e+02, -8.000e+00, -5.000e+00,\n        2.350e+02,  5.000e+00,  1.480e+02,  1.420e+02,  9.300e+01,\n       -4.172e+03,  4.500e+01,  2.800e+01,  2.500e+01,  1.100e+01,\n        5.000e+00,  5.900e+01,  1.700e+01,  2.000e+00,  2.250e+02,\n        1.050e+02,  4.000e+01,  3.000e+00,  5.200e+01,  2.500e+01,\n        5.000e+01, -4.000e+00,  1.000e+00,  6.000e+00, -1.000e+01,\n        3.100e+01,  4.000e+00,  4.000e+01, -1.088e+03,  3.600e+01,\n        3.680e+02,  6.600e+01,  4.900e+01,  3.300e+01, -7.000e+00,\n        2.600e+01,  1.420e+02,  0.000e+00,  1.200e+01, -6.000e+00,\n        8.000e+00,  3.000e+00,  1.360e+02,  1.500e+01,  2.600e+01],\n      dtype=float32)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_moves_data(\n",
    "    csv_filename=data_filename,\n",
    "    sample_size=100,\n",
    "    max_population=1000,\n",
    "    include_numeric=True,\n",
    "    include_fens=True,\n",
    "    vectorize_fens=False,\n",
    "    include_target=True,\n",
    "    split_X_y=True,\n",
    "    split_numeric_fens=True,\n",
    ")\n",
    "data[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test 1: Random Forest"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Prepare Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300000it [00:01, 263075.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting CSV rows to np.arrays...done.\n"
     ]
    }
   ],
   "source": [
    "''' Load data '''\n",
    "X, y = load_moves_data(csv_filename=data_filename,\n",
    "                       sample_size=3000,\n",
    "                       max_population=300_000,\n",
    "                       include_numeric=True,\n",
    "                       include_fens=False,\n",
    "                       include_target=True,\n",
    "                       split_X_y=True)\n",
    "\n",
    "''' Feature scaling '''\n",
    "# Taken from https://machinelearningmastery.com/how-to-improve-neural-network-stability-and-modeling-performance-with-data-scaling/\n",
    "scaler = skl.preprocessing.MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# TODO not sure if target col should be scaled?\n",
    "# scaler = skl.preprocessing.MinMaxScaler()\n",
    "# y_scaled = scaler.fit_transform(y.reshape((-1, 1))).ravel()\n",
    "\n",
    "''' Train/test/validate split '''\n",
    "# X_train, X_test_and_val, y_train, y_test_and_val = train_test_split(X_scaled, y_scaled, test_size=0.3, random_state=0)\n",
    "X_train, X_test_and_val, y_train, y_test_and_val = train_test_split(X_scaled, y, test_size=0.3, random_state=0)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test_and_val, y_test_and_val, test_size=0.5, random_state=0)\n",
    "\n",
    "''' Delete unneeded vars '''\n",
    "del X, y, X_test_and_val, y_test_and_val, X_scaled#, y_scaled"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (2100, 73)\n",
      "X_test.shape: (450, 73)\n",
      "X_val.shape: (450, 73)\n",
      "y_train.shape: (2100,)\n",
      "y_test.shape: (450,)\n",
      "y_val.shape: (450,)\n"
     ]
    }
   ],
   "source": [
    "# Check shapes\n",
    "print(f'X_train.shape: {X_train.shape}')\n",
    "print(f'X_test.shape: {X_test.shape}')\n",
    "print(f'X_val.shape: {X_val.shape}')\n",
    "print(f'y_train.shape: {y_train.shape}')\n",
    "print(f'y_test.shape: {y_test.shape}')\n",
    "print(f'y_val.shape: {y_val.shape}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1080x1080 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Optional: show feature correlation\n",
    "\n",
    "# Taken from https://towardsdatascience.com/deep-neural-networks-for-regression-problems-81321897ca33\n",
    "import seaborn as sb\n",
    "correlation_matrix = pd.DataFrame(data=X_train).corr()\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "sb.heatmap(correlation_matrix, vmax=0.8, square=True)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Fit Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "outputs": [],
   "source": [
    "# Note: MAE criterion 10x slower than MSE\n",
    "reg = RandomForestRegressor(n_estimators=100, criterion='mse')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "outputs": [
    {
     "data": {
      "text/plain": "RandomForestRegressor()"
     },
     "execution_count": 738,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit our training data using a random forest regression technique\n",
    "# Use only first 10k elements, otherwise it's very slow\n",
    "# (This takes around a minute to fit)\n",
    "reg.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "outputs": [],
   "source": [
    "# Predict the values of our testing set using the model\n",
    "y_pred = reg.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: -0.23208350020221546\n",
      "34 out of 450 are within 10 cp\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "print(f'r2_score: {r2_score(y_test, y_pred)}')\n",
    "\n",
    "# Check to see how many results are within the set range\n",
    "THRESHOLD = 10  # centipawns\n",
    "count = 0\n",
    "for i in range(0, len(y_pred)):\n",
    "    if abs(y_test[i] - y_pred[i]) <= THRESHOLD:\n",
    "        count += 1\n",
    "\n",
    "print(f'{count} out of {len(y_pred)} are within 10 cp')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Comparing the output from our predicted values to what they should be."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323.59 8034\n",
      "33.35 5\n",
      "160.8 12\n",
      "280.13 -11\n",
      "100.42 3\n",
      "101.08 363\n",
      "207.3 28\n",
      "3291.19 118\n",
      "1071.83 7692\n",
      "234.08 25\n",
      "23.07 20\n",
      "130.63 10\n",
      "42.2 4\n",
      "40.33 -3\n",
      "12.29 8\n",
      "62.84 2\n",
      "11.97 35\n",
      "410.17 4\n",
      "5.3 22\n",
      "30.89 27\n",
      "24.59 5\n",
      "1203.03 647\n",
      "86.23 5\n",
      "1129.58 -41\n",
      "70.14 26\n",
      "2731.34 -8581\n",
      "92.68 81\n",
      "20.12 28\n",
      "15.63 39\n",
      "664.5 -28\n",
      "29.19 1\n",
      "48.97 23\n",
      "25.61 -4\n",
      "58.04 27\n",
      "58.84 63\n",
      "789.4 3886\n",
      "280.43 522\n",
      "4602.13 8764\n",
      "269.87 9\n",
      "86.89 -15\n",
      "151.75 -47\n",
      "30.14 105\n",
      "13.53 -2\n",
      "176.96 -11\n",
      "225.04 60\n",
      "32.06 -2\n",
      "12.66 17\n",
      "145.18 -8\n",
      "6.11 5\n",
      "59.21 10\n",
      "340.86 173\n",
      "61.25 114\n",
      "51.11 86\n",
      "64.75 46\n",
      "144.54 19\n",
      "30.92 35\n",
      "26.9 31\n",
      "24.98 32\n",
      "357.32 6\n",
      "108.72 13\n",
      "111.99 0\n",
      "61.61 -16\n",
      "1324.08 295\n",
      "1748.9 288\n",
      "46.7 216\n",
      "29.24 30\n",
      "988.02 26\n",
      "19.51 3\n",
      "24.88 -2\n",
      "7.19 30\n",
      "1490.67 678\n",
      "22.59 13\n",
      "101.12 381\n",
      "112.21 48\n",
      "3451.07 -7233\n",
      "32.9 134\n",
      "1042.31 518\n",
      "29.61 3\n",
      "368.85 9\n",
      "77.71 49\n",
      "177.17 782\n",
      "396.34 14\n",
      "16.47 31\n",
      "84.6 -1\n",
      "29.2 43\n",
      "12.07 -2\n",
      "211.07 47\n",
      "41.16 548\n",
      "187.97 17\n",
      "36.22 56\n",
      "37.03 47\n",
      "18.38 7\n",
      "39.9 0\n",
      "113.69 -16\n",
      "417.02 5\n",
      "640.35 592\n",
      "42.42 0\n",
      "553.56 47\n",
      "445.56 104\n",
      "12.81 -5\n",
      "24.84 -8\n",
      "57.41 5\n",
      "675.53 46\n",
      "56.67 -8\n",
      "29.83 11\n",
      "2853.05 -1\n",
      "168.97 1051\n",
      "46.79 -7\n",
      "49.44 -21\n",
      "34.75 -1\n",
      "100.46 399\n",
      "97.11 109\n",
      "158.18 4\n",
      "12.82 4\n",
      "598.78 8968\n",
      "152.55 -5\n",
      "273.2 0\n",
      "41.78 -3\n",
      "170.6 18\n",
      "449.8 8\n",
      "131.31 27\n",
      "18.71 5\n",
      "1830.43 8109\n",
      "22.63 69\n",
      "18.14 2\n",
      "26.91 18\n",
      "373.36 23\n",
      "23.4 12\n",
      "19.84 9\n",
      "17.13 31\n",
      "82.14 -5\n",
      "262.2 13\n",
      "2495.08 284\n",
      "13.24 13\n",
      "6.43 -11\n",
      "227.76 15\n",
      "20.32 6\n",
      "23.34 80\n",
      "22.39 37\n",
      "18.1 9\n",
      "30.48 51\n",
      "18.56 -1\n",
      "231.42 108\n",
      "1327.79 0\n",
      "42.46 23\n",
      "20.51 10\n",
      "49.34 9\n",
      "34.14 1\n",
      "38.83 37\n",
      "1398.34 -10\n",
      "15.62 14\n",
      "578.17 4\n",
      "103.76 62\n",
      "7.61 17\n",
      "40.47 18\n",
      "62.01 453\n",
      "41.95 1\n",
      "79.12 79\n",
      "29.02 8\n",
      "8.26 60\n",
      "15.44 18\n",
      "24.62 -7\n",
      "25.8 5\n",
      "22.24 51\n",
      "283.32 246\n",
      "138.37 -3\n",
      "32.53 37\n",
      "39.74 -7\n",
      "92.2 95\n",
      "1292.71 333\n",
      "257.86 82\n",
      "164.72 162\n",
      "5.53 5\n",
      "61.52 9\n",
      "8.22 13\n",
      "41.68 -15\n",
      "70.89 -11\n",
      "441.34 -1\n",
      "1378.85 23\n",
      "31.47 28\n",
      "237.71 6\n",
      "131.54 73\n",
      "356.6 -25\n",
      "46.44 155\n",
      "1271.17 -2\n",
      "30.78 -8\n",
      "16.13 74\n",
      "54.19 6\n",
      "522.94 -39\n",
      "242.74 9389\n",
      "425.11 114\n",
      "25.24 6\n",
      "40.65 17\n",
      "938.39 -1\n",
      "250.92 112\n",
      "7.31 6\n",
      "44.98 62\n",
      "35.45 108\n",
      "10.43 33\n",
      "804.78 921\n",
      "25.01 13\n",
      "37.59 3\n",
      "526.93 -9\n",
      "39.65 -6\n",
      "232.14 103\n",
      "37.51 44\n",
      "22.99 10\n",
      "22.91 16\n",
      "39.02 1\n",
      "76.72 27\n",
      "3003.83 85\n",
      "495.84 1\n",
      "86.43 -15\n",
      "42.57 113\n",
      "264.76 27\n",
      "281.29 142\n",
      "309.39 387\n",
      "27.93 5\n",
      "302.66 169\n",
      "77.16 79\n",
      "2236.78 9216\n",
      "17.89 67\n",
      "55.74 34\n",
      "39.74 0\n",
      "27.28 35\n",
      "63.98 3\n",
      "12.8 38\n",
      "16.47 20\n",
      "160.3 13\n",
      "13.24 3\n",
      "917.72 -17\n",
      "953.09 55\n",
      "500.77 28\n",
      "43.38 9\n",
      "18.61 43\n",
      "218.25 -11\n",
      "26.08 -2\n",
      "17.41 77\n",
      "1167.16 -1\n",
      "90.48 106\n",
      "16.06 21\n",
      "5.55 -11\n",
      "22.7 26\n",
      "654.05 28\n",
      "1143.25 -73\n",
      "37.36 95\n",
      "25.37 17\n",
      "425.43 11\n",
      "152.76 146\n",
      "56.05 -11\n",
      "75.48 106\n",
      "257.36 45\n",
      "38.25 -10\n",
      "68.89 0\n",
      "194.79 957\n",
      "102.14 1\n",
      "913.0 80\n",
      "24.23 29\n",
      "35.86 -5\n",
      "144.9 148\n",
      "56.42 73\n",
      "24.94 3\n",
      "317.43 -151\n",
      "30.07 5\n",
      "39.81 15\n",
      "108.48 2\n",
      "26.39 10\n",
      "71.33 1\n",
      "36.39 6\n",
      "28.49 56\n",
      "106.2 0\n",
      "324.8 -12\n",
      "53.48 1\n",
      "15.44 17\n",
      "380.67 -17\n",
      "24.53 -12\n",
      "28.99 47\n",
      "31.09 -1\n",
      "69.08 59\n",
      "11.67 -8\n",
      "16.93 51\n",
      "104.75 8\n",
      "86.3 14\n",
      "472.34 10\n",
      "10.17 -15\n",
      "12.5 -2\n",
      "296.01 74\n",
      "4.18 7\n",
      "26.38 47\n",
      "380.84 28\n",
      "124.75 -161\n",
      "198.92 5\n",
      "1188.23 3392\n",
      "81.62 110\n",
      "2492.95 5\n",
      "31.62 44\n",
      "169.07 87\n",
      "47.1 29\n",
      "943.21 90\n",
      "51.84 82\n",
      "76.08 47\n",
      "11.54 1\n",
      "210.21 -134\n",
      "26.76 13\n",
      "22.9 -6\n",
      "30.05 19\n",
      "36.2 15\n",
      "134.73 14\n",
      "288.86 32\n",
      "19.87 22\n",
      "78.77 42\n",
      "43.13 24\n",
      "47.39 53\n",
      "18.69 217\n",
      "47.26 -5\n",
      "48.54 16\n",
      "1400.23 2\n",
      "50.47 10\n",
      "8.52 23\n",
      "22.56 25\n",
      "9.61 77\n",
      "69.31 4\n",
      "172.99 96\n",
      "556.21 416\n",
      "90.6 7\n",
      "476.42 -9\n",
      "299.91 9633\n",
      "39.91 23\n",
      "7.48 -3\n",
      "531.57 -40\n",
      "119.73 147\n",
      "129.19 21\n",
      "996.23 17\n",
      "78.31 28\n",
      "22.97 19\n",
      "377.63 848\n",
      "12.13 15\n",
      "138.84 22\n",
      "39.29 28\n",
      "-11.9 62\n",
      "9.65 43\n",
      "50.29 43\n",
      "46.02 29\n",
      "15.47 26\n",
      "-332.17 190\n",
      "23.63 24\n",
      "12.9 1\n",
      "86.21 3\n",
      "28.85 97\n",
      "42.0 10\n",
      "33.27 60\n",
      "15.63 -11\n",
      "32.09 4\n",
      "23.89 3\n",
      "73.01 33\n",
      "64.21 49\n",
      "28.64 0\n",
      "13.7 34\n",
      "56.96 55\n",
      "14.42 18\n",
      "29.85 -12\n",
      "33.56 14\n",
      "13.28 27\n",
      "30.2 22\n",
      "41.63 35\n",
      "144.42 -15\n",
      "36.88 28\n",
      "19.21 32\n",
      "533.09 87\n",
      "133.86 140\n",
      "26.49 25\n",
      "13.37 22\n",
      "26.22 9\n",
      "15.71 5\n",
      "111.18 22\n",
      "2812.33 -29\n",
      "100.82 -14\n",
      "2093.91 9013\n",
      "310.06 -36\n",
      "61.63 67\n",
      "31.65 1216\n",
      "24.52 12\n",
      "50.74 -4\n",
      "72.58 28\n",
      "105.53 32\n",
      "44.22 313\n",
      "60.82 24\n",
      "20.29 25\n",
      "59.7 22\n",
      "1285.25 2788\n",
      "61.79 29\n",
      "68.85 9\n",
      "559.6 201\n",
      "178.3 297\n",
      "1289.89 363\n",
      "2158.8 0\n",
      "107.75 12\n",
      "37.85 41\n",
      "126.24 -6\n",
      "1199.16 6\n",
      "128.11 236\n",
      "264.95 105\n",
      "23.17 161\n",
      "33.04 4\n",
      "99.89 62\n",
      "24.43 -7\n",
      "1147.75 2\n",
      "1308.2 -19\n",
      "14.82 27\n",
      "70.55 -7\n",
      "2116.44 388\n",
      "45.99 116\n",
      "45.03 44\n",
      "1919.72 -5\n",
      "1704.88 9368\n",
      "88.45 -2\n",
      "69.09 50\n",
      "78.1 16\n",
      "16.71 2\n",
      "84.09 121\n",
      "1581.15 1290\n",
      "11.24 24\n",
      "346.03 16\n",
      "88.96 7\n",
      "17.53 0\n",
      "17.61 -7\n",
      "403.53 59\n",
      "3916.9 366\n",
      "10.92 2\n",
      "17.18 22\n",
      "244.07 -6\n",
      "23.23 604\n",
      "37.31 13\n",
      "6.93 7\n",
      "28.07 -20\n",
      "28.78 10\n",
      "34.28 -4\n",
      "15.99 2\n",
      "74.51 201\n",
      "78.35 7\n",
      "49.51 -14\n",
      "3169.06 -8141\n",
      "40.57 2\n",
      "245.4 -15\n",
      "28.8 241\n",
      "41.73 -8\n",
      "44.68 34\n",
      "-346.92 -12\n",
      "1767.09 -3\n",
      "48.48 -3\n",
      "42.48 -1\n",
      "59.74 319\n",
      "16.02 -10\n",
      "-59.61 -1\n",
      "1957.3 9733\n",
      "19.59 2\n",
      "23.0 8\n",
      "78.25 8\n",
      "79.88 184\n",
      "93.86 335\n",
      "36.13 15\n",
      "64.09 13\n",
      "21.83 0\n",
      "19.2 13\n",
      "38.03 15\n",
      "114.05 82\n",
      "22.93 24\n",
      "1039.99 -64\n",
      "169.76 0\n",
      "39.78 4\n",
      "896.59 831\n",
      "41.7 166\n",
      "86.29 -6\n",
      "73.98 65\n",
      "220.94 -2\n",
      "21.74 -9\n",
      "47.43 0\n",
      "18.29 142\n",
      "42.86 6\n",
      "29.97 43\n",
      "124.64 22\n",
      "281.99 -8\n",
      "207.34 275\n",
      "30.53 -10\n",
      "74.43 0\n",
      "47.7 99\n",
      "124.29 152\n",
      "1281.53 16\n",
      "61.1 58\n",
      "190.06 68\n",
      "41.13 0\n",
      "622.07 -21\n",
      "122.26 -13\n",
      "10.72 273\n",
      "61.52 44\n",
      "26.85 0\n",
      "30.34 33\n",
      "23.97 -7\n",
      "17.52 19\n",
      "2.99 -5\n",
      "46.45 67\n",
      "6.96 -1\n",
      "99.15 505\n",
      "23.92 15\n",
      "290.92 29\n",
      "21.27 3\n",
      "12.32 5\n",
      "10.63 2\n",
      "471.82 8\n",
      "72.72 60\n",
      "25.5 27\n",
      "458.99 9482\n",
      "2148.28 5\n",
      "824.5 -139\n",
      "47.21 31\n",
      "27.19 5\n",
      "439.06 121\n",
      "110.89 124\n",
      "76.07 54\n",
      "578.19 38\n",
      "174.56 183\n",
      "19.84 111\n",
      "1561.68 223\n",
      "240.74 99\n",
      "126.26 195\n",
      "43.19 -4\n",
      "9.18 16\n",
      "129.11 -5\n",
      "172.21 42\n",
      "174.43 -4\n",
      "46.75 3\n",
      "13.63 0\n",
      "38.75 62\n",
      "23.32 14\n",
      "43.11 72\n",
      "43.6 23\n",
      "252.43 151\n",
      "185.69 217\n",
      "75.35 67\n",
      "63.23 -9\n",
      "94.65 45\n",
      "98.54 314\n",
      "143.38 68\n",
      "17.28 17\n",
      "39.27 -2\n",
      "57.07 -14\n",
      "30.4 22\n",
      "41.7 39\n",
      "64.22 31\n",
      "13.69 0\n",
      "25.8 2\n",
      "79.39 19\n",
      "238.16 3\n",
      "12.75 -7\n",
      "49.5 4\n",
      "33.16 9\n",
      "48.83 44\n",
      "907.49 -30\n",
      "345.32 573\n",
      "98.36 264\n",
      "16.44 20\n",
      "50.54 55\n",
      "54.84 30\n",
      "59.99 27\n",
      "25.3 0\n",
      "25.32 126\n",
      "956.27 189\n",
      "30.06 -4\n",
      "26.19 -17\n",
      "69.59 -4\n",
      "29.46 7\n",
      "88.61 93\n",
      "119.4 -3\n",
      "36.04 49\n",
      "39.03 19\n",
      "1898.07 14\n",
      "1391.94 -4193\n",
      "2757.1 389\n",
      "1012.79 16\n",
      "21.1 47\n",
      "532.31 -47\n",
      "71.82 -31\n",
      "11.89 -6\n",
      "128.83 177\n",
      "347.02 -1\n",
      "817.29 -93\n",
      "15.04 7\n",
      "153.24 67\n",
      "33.43 32\n",
      "8.51 29\n",
      "45.9 97\n",
      "105.88 -1\n",
      "28.88 5\n",
      "74.51 17\n",
      "244.21 5\n",
      "151.47 15\n",
      "260.17 36\n",
      "230.66 117\n",
      "10.4 13\n",
      "216.25 6\n",
      "165.37 7\n",
      "1067.75 7902\n",
      "17.11 -1\n",
      "33.37 -4\n",
      "6.6 -6\n",
      "513.81 10\n",
      "12.46 -7\n",
      "736.5 -57\n",
      "31.05 51\n",
      "14.09 5\n",
      "325.09 215\n",
      "1496.4 -6\n",
      "101.8 194\n",
      "149.61 32\n",
      "27.9 39\n",
      "27.53 1\n",
      "54.18 -3\n",
      "1331.56 1\n",
      "1088.46 19\n",
      "858.85 10\n",
      "77.94 49\n",
      "11.38 25\n",
      "760.81 58\n",
      "49.39 18\n",
      "24.25 118\n",
      "19.91 6\n",
      "165.0 116\n",
      "10.19 13\n",
      "179.43 8\n",
      "61.22 442\n",
      "47.74 65\n",
      "139.78 18\n",
      "1763.33 147\n",
      "264.43 10\n",
      "101.92 453\n",
      "103.48 -16\n",
      "31.46 -3\n",
      "48.24 29\n",
      "402.58 35\n",
      "24.78 -18\n",
      "56.59 120\n",
      "8.94 -6\n",
      "338.53 -4\n",
      "2220.93 -1\n",
      "47.82 20\n",
      "30.52 12\n",
      "1453.14 405\n",
      "233.35 -7\n",
      "114.26 51\n",
      "42.56 60\n",
      "46.11 -25\n",
      "427.93 -1\n",
      "24.81 -3\n",
      "1167.02 190\n",
      "51.3 6\n",
      "8.42 6\n",
      "57.39 72\n",
      "1126.33 38\n",
      "145.76 48\n",
      "2.76 29\n",
      "29.07 -4\n",
      "45.78 19\n",
      "693.91 6\n",
      "75.04 2\n",
      "53.38 -23\n",
      "61.68 25\n",
      "305.46 11\n",
      "62.83 -12\n",
      "50.33 43\n",
      "35.04 4\n",
      "1600.9 -5\n",
      "21.75 44\n",
      "19.7 52\n",
      "8.74 -6\n",
      "49.53 7\n",
      "24.35 24\n",
      "180.29 26\n",
      "41.22 3\n",
      "18.66 -6\n",
      "52.16 0\n",
      "488.97 236\n",
      "45.03 584\n",
      "8.94 -4\n",
      "-212.33 103\n",
      "64.08 -4\n",
      "549.47 3\n",
      "20.64 11\n",
      "557.38 9\n",
      "6.79 -3\n",
      "47.54 -10\n",
      "63.04 24\n",
      "18.88 48\n",
      "289.69 12\n",
      "842.46 84\n",
      "44.77 80\n",
      "191.33 5\n",
      "397.65 0\n",
      "12.89 -2\n",
      "15.52 7\n",
      "56.18 173\n",
      "1121.33 40\n",
      "1319.95 0\n",
      "4504.74 9\n",
      "68.34 132\n",
      "56.87 19\n",
      "26.44 17\n",
      "56.81 2\n",
      "94.24 0\n",
      "362.93 -42\n",
      "38.62 29\n",
      "70.82 32\n",
      "73.64 72\n",
      "1184.35 39\n",
      "49.83 -4\n",
      "44.15 14\n",
      "48.55 41\n",
      "1022.73 315\n",
      "15.74 3\n",
      "159.58 969\n",
      "10.04 5\n",
      "57.73 173\n",
      "327.62 49\n",
      "2849.46 -1\n",
      "85.65 30\n",
      "32.09 23\n",
      "34.02 10\n",
      "317.55 8\n",
      "902.74 198\n",
      "44.42 8\n",
      "327.54 593\n",
      "40.2 -7\n",
      "34.64 19\n",
      "59.65 -7\n",
      "9.77 49\n",
      "17.72 22\n",
      "14.9 5\n",
      "30.84 39\n",
      "9.87 20\n",
      "165.62 9191\n",
      "39.84 -3\n",
      "43.78 17\n",
      "44.51 3\n",
      "73.7 30\n",
      "87.98 -7\n",
      "35.5 10\n",
      "68.34 14\n",
      "13.85 -1\n",
      "510.91 440\n",
      "30.98 140\n",
      "27.43 -9\n",
      "256.73 -23\n",
      "775.36 -4\n",
      "112.58 -5\n",
      "415.84 -8\n",
      "146.21 278\n",
      "99.11 9\n",
      "43.27 62\n",
      "64.22 0\n",
      "11.39 12\n",
      "96.15 3\n",
      "422.26 4869\n",
      "20.61 13\n",
      "30.03 28\n",
      "62.19 114\n",
      "149.5 -3\n",
      "88.89 76\n",
      "228.15 9\n",
      "54.51 1\n",
      "87.86 7\n",
      "19.57 16\n",
      "67.6 -3\n",
      "62.96 -5\n",
      "31.56 6\n",
      "59.45 38\n",
      "40.46 7\n",
      "19.65 10\n",
      "68.57 619\n",
      "667.58 0\n",
      "9.3 -3\n",
      "39.17 4\n",
      "44.75 47\n",
      "2272.75 -4\n",
      "37.83 -2\n",
      "107.21 29\n",
      "707.06 0\n",
      "90.02 23\n",
      "0.66 -2\n",
      "58.69 12\n",
      "29.28 34\n",
      "37.1 24\n",
      "34.33 -6\n",
      "39.52 65\n",
      "14.99 33\n",
      "9.21 30\n",
      "476.95 263\n",
      "27.53 10\n",
      "8.56 29\n",
      "87.99 11\n",
      "261.36 2\n",
      "72.19 529\n",
      "54.28 11\n",
      "637.68 679\n",
      "628.26 281\n",
      "74.57 -18\n",
      "42.12 391\n",
      "143.97 -8\n",
      "583.86 87\n",
      "346.67 -18\n",
      "141.77 86\n",
      "40.04 -8\n",
      "19.0 102\n",
      "91.5 9\n",
      "79.17 38\n",
      "24.93 28\n",
      "20.98 -2\n",
      "79.2 22\n",
      "48.62 -1\n",
      "644.47 5\n",
      "144.6 -5\n",
      "12.37 45\n",
      "52.88 24\n",
      "19.77 139\n",
      "6.36 1\n",
      "79.41 5\n",
      "43.74 0\n",
      "23.89 23\n",
      "13.52 9\n",
      "88.26 44\n",
      "761.93 198\n",
      "36.54 68\n",
      "36.1 61\n",
      "891.71 284\n",
      "39.0 9\n",
      "39.03 9\n",
      "38.38 14\n",
      "28.77 61\n",
      "82.27 320\n",
      "34.11 4\n",
      "25.23 43\n",
      "277.5 249\n",
      "87.8 135\n",
      "103.91 23\n",
      "342.56 50\n",
      "118.3 98\n",
      "1301.19 5\n",
      "13.39 8\n",
      "13.99 2\n",
      "57.2 9\n",
      "14.01 8\n",
      "1553.33 -43\n",
      "796.05 894\n",
      "83.09 70\n",
      "46.0 0\n",
      "19.91 49\n",
      "275.69 21\n",
      "18.42 2\n",
      "36.73 106\n",
      "13.69 23\n",
      "80.48 -4\n",
      "16.33 8\n",
      "30.84 28\n",
      "12.14 -3\n",
      "11.85 16\n",
      "53.79 14\n",
      "26.34 8\n",
      "163.24 167\n",
      "77.51 4\n",
      "32.31 30\n",
      "14.05 6\n",
      "2573.79 6\n",
      "402.46 -20\n",
      "181.91 127\n",
      "65.16 58\n",
      "53.74 29\n",
      "349.21 4\n",
      "101.35 -6\n",
      "17.63 3\n",
      "69.87 -91\n",
      "762.42 -110\n",
      "1205.43 167\n",
      "324.89 -4\n",
      "93.23 -7\n",
      "252.29 0\n",
      "53.14 35\n",
      "22.17 22\n",
      "22.28 24\n",
      "76.22 12\n",
      "8.96 -12\n",
      "3864.36 218\n",
      "21.87 33\n",
      "13.27 102\n",
      "1187.77 -1\n",
      "1153.21 77\n",
      "3063.49 52\n",
      "75.01 110\n",
      "33.95 4\n",
      "103.36 5\n",
      "29.14 -4\n",
      "15.73 7\n",
      "4.46 -14\n",
      "2424.83 8385\n",
      "1130.28 1095\n",
      "105.45 49\n",
      "87.81 14\n",
      "23.32 34\n",
      "57.18 14\n",
      "27.87 1\n",
      "1466.42 261\n",
      "233.57 147\n",
      "110.78 51\n",
      "9.67 -6\n",
      "88.58 -7\n",
      "38.18 111\n",
      "45.01 31\n",
      "85.07 8\n",
      "12.59 24\n",
      "17.46 15\n",
      "74.28 0\n",
      "20.31 10\n",
      "38.69 -4\n",
      "2261.2 8095\n",
      "336.72 27\n",
      "57.91 114\n",
      "244.55 4\n",
      "109.29 73\n",
      "194.77 184\n",
      "42.48 76\n",
      "18.52 487\n",
      "30.88 95\n",
      "35.01 50\n",
      "44.8 -20\n",
      "45.96 17\n",
      "263.72 -7\n",
      "702.42 -12\n",
      "24.07 24\n",
      "124.78 25\n",
      "66.21 136\n",
      "94.31 27\n",
      "856.16 24\n",
      "21.97 46\n",
      "286.89 42\n",
      "28.16 24\n",
      "131.97 8\n",
      "234.61 6\n",
      "119.19 0\n",
      "913.91 4967\n",
      "40.43 69\n",
      "422.08 22\n",
      "14.25 24\n",
      "21.75 0\n",
      "2449.14 43\n",
      "26.11 -20\n",
      "38.31 144\n",
      "14.54 8\n",
      "5.94 16\n",
      "22.92 -9\n",
      "22.42 1\n",
      "22.71 106\n",
      "84.99 -1\n",
      "18.77 11\n",
      "67.03 76\n",
      "11.82 -5\n",
      "1457.31 119\n",
      "3801.73 200\n",
      "126.95 -9\n",
      "181.83 0\n",
      "12.41 -3\n",
      "251.67 -200\n",
      "41.09 16\n",
      "50.67 59\n",
      "15.71 33\n",
      "10.38 0\n",
      "19.9 -1\n",
      "61.31 -3\n",
      "828.01 121\n",
      "36.01 -6\n",
      "265.27 2204\n",
      "32.26 -7\n",
      "738.2 -15\n",
      "81.14 26\n",
      "67.88 327\n",
      "72.8 86\n",
      "324.46 0\n",
      "137.48 134\n",
      "18.47 11\n",
      "27.89 92\n",
      "96.67 20\n",
      "844.04 14\n",
      "71.36 332\n",
      "828.73 1406\n",
      "159.24 365\n",
      "58.97 -3\n",
      "185.57 -7\n",
      "44.91 9\n",
      "384.94 345\n",
      "21.9 7\n",
      "66.66 4\n",
      "47.04 45\n",
      "9.25 20\n",
      "43.44 98\n",
      "25.66 10\n",
      "17.42 24\n",
      "37.74 85\n",
      "263.6 -11\n",
      "16.65 1\n",
      "53.62 109\n",
      "30.47 5\n",
      "59.5 12\n",
      "239.63 162\n",
      "12.0 56\n",
      "15.16 0\n",
      "111.62 29\n",
      "65.39 13\n",
      "15.71 5\n",
      "104.45 -3\n",
      "24.81 -8\n",
      "205.03 -1\n",
      "427.88 120\n",
      "48.69 73\n",
      "26.38 -20\n",
      "12.62 -5\n",
      "26.14 -6\n",
      "71.77 10\n",
      "68.52 25\n",
      "213.66 30\n",
      "223.25 82\n",
      "295.12 70\n",
      "1606.67 84\n",
      "16.86 -1\n",
      "27.19 -4\n",
      "43.08 7\n",
      "40.23 13\n",
      "11.28 -1\n",
      "182.34 -1\n",
      "83.18 10\n",
      "1383.55 304\n",
      "51.2 2\n",
      "17.17 15\n",
      "10.08 45\n",
      "11.93 6\n",
      "-37.13 -1\n",
      "28.82 101\n",
      "24.77 17\n",
      "17.22 10\n",
      "53.5 33\n",
      "32.79 -7\n",
      "116.12 4306\n",
      "320.33 175\n",
      "96.25 69\n",
      "285.04 188\n",
      "53.4 89\n",
      "534.61 192\n",
      "1073.07 -88\n",
      "50.76 53\n",
      "216.31 709\n",
      "1325.43 -6\n",
      "49.4 333\n",
      "116.91 38\n",
      "48.48 16\n",
      "46.15 -8\n",
      "13.39 -4\n",
      "124.62 373\n",
      "952.75 370\n",
      "187.68 13\n",
      "31.17 34\n",
      "67.71 150\n",
      "24.26 93\n",
      "673.28 -1\n",
      "83.87 21\n",
      "26.64 -1\n",
      "244.4 58\n",
      "11.23 36\n",
      "5.43 45\n",
      "66.45 57\n",
      "5.57 -6\n",
      "351.43 852\n",
      "297.39 26\n",
      "775.25 25\n",
      "7.28 -2\n",
      "78.12 -6\n",
      "20.15 4\n",
      "8.94 -8\n",
      "42.68 -5\n",
      "38.52 6\n",
      "34.9 -1\n",
      "18.45 13\n",
      "64.7 75\n",
      "6.94 5\n",
      "50.49 28\n",
      "13.69 17\n",
      "537.25 126\n",
      "83.36 37\n",
      "23.86 -5\n",
      "64.85 9\n",
      "245.58 -11\n",
      "318.59 104\n",
      "243.7 -3\n",
      "821.77 75\n",
      "56.85 -1\n",
      "33.51 112\n",
      "86.45 14\n",
      "78.93 25\n",
      "548.56 57\n",
      "56.39 -5\n",
      "24.71 0\n",
      "35.33 -9\n",
      "209.95 38\n",
      "26.83 0\n",
      "105.22 0\n",
      "13.48 -2\n",
      "440.39 43\n",
      "38.25 18\n",
      "63.3 154\n",
      "15.96 66\n",
      "22.69 46\n",
      "28.09 24\n",
      "218.42 3\n",
      "238.97 85\n",
      "120.06 18\n",
      "33.93 120\n",
      "75.99 166\n",
      "123.54 46\n",
      "28.86 7\n",
      "17.26 9\n",
      "55.56 -23\n",
      "114.38 27\n",
      "10.92 27\n",
      "59.45 9\n",
      "72.38 -12\n",
      "64.3 16\n",
      "10.16 -1\n",
      "15.8 -22\n",
      "461.13 71\n",
      "31.09 21\n",
      "73.09 18\n",
      "32.4 19\n",
      "11.08 2\n",
      "94.41 53\n",
      "22.75 38\n",
      "26.01 5\n",
      "1130.23 8435\n",
      "45.56 25\n",
      "1380.56 -1\n",
      "214.65 16\n",
      "1119.58 -1\n",
      "90.69 29\n",
      "21.08 -1\n",
      "62.05 -8\n",
      "150.63 32\n",
      "37.74 12\n",
      "6.02 35\n",
      "146.15 -26\n",
      "119.51 208\n",
      "27.77 88\n",
      "1965.61 166\n",
      "35.49 45\n",
      "345.43 35\n",
      "94.48 1\n",
      "40.4 16\n",
      "709.63 -1\n",
      "23.33 18\n",
      "471.13 247\n",
      "28.32 -7\n",
      "134.59 2\n",
      "612.99 136\n",
      "27.26 65\n",
      "85.62 14\n",
      "21.58 16\n",
      "33.93 49\n",
      "26.55 18\n",
      "37.29 15\n",
      "24.91 20\n",
      "74.47 7\n",
      "124.24 33\n",
      "15.19 22\n",
      "37.76 22\n",
      "13.7 13\n",
      "57.14 18\n",
      "-3.79 53\n",
      "47.51 691\n",
      "13.93 12\n",
      "79.47 7\n",
      "22.03 2\n",
      "41.37 -4\n",
      "96.42 19\n",
      "28.55 11\n",
      "39.94 6\n",
      "31.3 189\n",
      "13.43 13\n",
      "59.58 55\n",
      "652.49 7669\n",
      "87.43 -3\n",
      "1757.98 287\n",
      "165.42 219\n",
      "23.52 14\n",
      "19.31 42\n",
      "39.06 -9\n",
      "25.59 -1\n",
      "26.54 -2\n",
      "43.47 2\n",
      "301.87 9\n",
      "28.38 24\n",
      "19.64 2\n",
      "7.36 11\n",
      "13.31 1\n",
      "1695.23 234\n",
      "18.67 -4\n",
      "100.44 31\n",
      "54.62 167\n",
      "83.34 143\n",
      "18.19 0\n",
      "35.23 7\n",
      "35.24 8\n",
      "13.7 9\n",
      "63.45 468\n",
      "1355.04 688\n",
      "595.95 0\n",
      "785.67 0\n",
      "402.78 67\n",
      "44.95 -6\n",
      "175.89 -1\n",
      "865.13 -8\n",
      "65.22 111\n",
      "18.14 -2\n",
      "48.33 162\n",
      "167.8 9972\n",
      "716.45 101\n",
      "14.04 12\n",
      "4172.64 -2\n",
      "17.37 5\n",
      "87.59 2\n",
      "234.82 4\n",
      "83.08 2\n",
      "659.01 0\n",
      "14.34 -7\n",
      "28.31 15\n",
      "319.62 9642\n",
      "50.19 -15\n",
      "135.38 69\n",
      "505.04 2153\n",
      "414.17 13\n",
      "142.19 26\n",
      "17.39 -6\n",
      "1096.74 16\n",
      "55.9 68\n",
      "40.37 323\n",
      "132.97 143\n",
      "54.87 2\n",
      "208.35 9609\n",
      "55.01 20\n",
      "96.27 10\n",
      "1079.29 -1\n",
      "670.53 614\n",
      "15.71 46\n",
      "282.97 27\n",
      "906.97 5276\n",
      "92.21 9\n",
      "185.19 17\n",
      "75.58 -8\n",
      "54.33 9\n",
      "39.73 23\n",
      "3137.25 8313\n",
      "112.13 -23\n",
      "787.05 3881\n",
      "65.17 68\n",
      "52.88 97\n",
      "56.63 59\n",
      "51.44 20\n",
      "693.59 29\n",
      "885.77 4\n",
      "741.35 97\n",
      "199.2 -2\n",
      "5.69 18\n",
      "16.14 21\n",
      "28.14 28\n",
      "1.59 74\n",
      "23.62 43\n",
      "20.88 60\n",
      "92.52 -1\n",
      "46.02 183\n",
      "9.56 6\n",
      "46.23 5\n",
      "61.34 3\n",
      "317.18 2\n",
      "31.1 0\n",
      "37.67 66\n",
      "210.85 -3\n",
      "40.72 82\n",
      "1265.91 -21\n",
      "44.12 3\n",
      "56.98 -15\n",
      "28.11 -4\n",
      "94.25 16\n",
      "79.32 155\n",
      "88.93 -5\n",
      "23.34 0\n",
      "865.9 3\n",
      "25.19 3\n",
      "45.97 -7\n",
      "3373.0 -33\n",
      "21.83 -7\n",
      "156.55 94\n",
      "37.63 147\n",
      "21.02 21\n",
      "10.75 0\n",
      "150.48 16\n",
      "54.25 15\n",
      "17.25 13\n",
      "2106.89 1\n",
      "3285.79 5539\n",
      "43.29 136\n",
      "3977.08 110\n",
      "19.88 30\n",
      "282.46 523\n",
      "977.72 -2\n",
      "19.1 20\n",
      "74.5 -12\n",
      "37.51 7\n",
      "42.66 -9\n",
      "20.3 16\n",
      "88.79 -16\n",
      "69.38 37\n",
      "115.07 165\n",
      "17.83 29\n",
      "37.8 134\n",
      "169.36 -12\n",
      "23.29 2\n",
      "90.85 4\n",
      "80.53 26\n",
      "8.57 11\n",
      "27.58 2\n",
      "52.3 0\n",
      "26.43 12\n",
      "7.67 5\n",
      "58.87 13\n",
      "205.13 104\n",
      "26.35 7\n",
      "2700.18 871\n",
      "26.14 274\n",
      "24.96 15\n",
      "84.68 92\n",
      "179.69 142\n",
      "45.44 48\n",
      "298.41 -2\n",
      "63.63 -11\n",
      "62.06 19\n",
      "11.4 5\n",
      "15.52 14\n",
      "679.97 11\n",
      "1070.87 4\n",
      "157.7 34\n",
      "249.76 350\n",
      "81.08 87\n",
      "11.44 43\n",
      "2414.39 167\n",
      "32.1 79\n",
      "30.99 -1\n",
      "19.78 -3\n",
      "126.94 11\n",
      "48.98 0\n",
      "17.3 45\n",
      "132.62 13\n",
      "4.69 16\n",
      "44.6 16\n",
      "2.05 1\n",
      "53.65 129\n",
      "1840.03 -1\n",
      "26.36 300\n",
      "69.65 175\n",
      "447.16 134\n",
      "674.4 36\n",
      "52.86 -8\n",
      "16.62 12\n",
      "288.21 488\n",
      "186.23 101\n",
      "93.53 5\n",
      "365.82 4\n",
      "37.9 -4\n",
      "677.23 101\n",
      "102.41 32\n",
      "318.7 246\n",
      "17.12 23\n",
      "27.05 -5\n",
      "16.89 -18\n",
      "125.02 365\n",
      "22.23 24\n",
      "1393.33 220\n",
      "16.03 35\n",
      "2.67 4\n",
      "39.01 133\n",
      "84.9 73\n",
      "14.75 -9\n",
      "38.59 17\n",
      "1438.37 2\n",
      "2138.52 -58\n",
      "34.64 34\n",
      "63.0 5\n",
      "18.41 0\n",
      "40.64 17\n",
      "20.0 31\n",
      "15.67 74\n",
      "893.23 1060\n",
      "397.09 266\n",
      "48.42 81\n",
      "70.77 15\n",
      "29.7 86\n",
      "41.22 18\n",
      "45.13 -5\n",
      "43.19 23\n",
      "28.08 -4\n",
      "411.61 1172\n",
      "38.76 10\n",
      "59.57 39\n",
      "46.37 0\n",
      "74.35 377\n",
      "20.93 11\n",
      "91.39 81\n",
      "25.62 28\n",
      "6.84 -1\n",
      "26.7 74\n",
      "11.92 2\n",
      "26.06 7\n",
      "18.75 21\n",
      "13.44 18\n",
      "26.05 -6\n",
      "29.99 4\n",
      "6.04 -1\n",
      "32.94 -2\n",
      "21.06 11\n",
      "254.81 154\n",
      "38.88 45\n",
      "72.25 -10\n",
      "60.1 3\n",
      "29.78 30\n",
      "159.8 149\n",
      "10.7 18\n",
      "145.45 223\n",
      "16.54 29\n",
      "243.72 42\n",
      "337.92 1157\n",
      "138.51 16\n",
      "429.92 92\n",
      "12.75 1\n",
      "39.58 16\n",
      "29.28 2\n",
      "134.51 6\n",
      "44.06 48\n",
      "23.65 13\n",
      "111.56 25\n",
      "95.01 -3\n",
      "16.97 9\n",
      "702.81 4388\n",
      "16.54 15\n",
      "49.63 98\n",
      "59.14 7\n",
      "14.3 -5\n",
      "222.7 201\n",
      "79.33 212\n",
      "39.67 106\n",
      "1497.17 156\n",
      "19.88 12\n",
      "63.93 73\n",
      "810.92 84\n",
      "33.7 6\n",
      "17.45 24\n",
      "41.46 4\n",
      "30.88 31\n",
      "504.51 -3\n",
      "105.25 43\n",
      "61.33 20\n",
      "51.58 20\n",
      "393.74 90\n",
      "1195.54 17\n",
      "660.11 10501\n",
      "47.39 21\n",
      "80.94 92\n",
      "34.71 -14\n",
      "164.58 64\n",
      "273.31 -8\n",
      "96.29 981\n",
      "52.51 -5\n",
      "9.17 2\n",
      "4.18 -4\n",
      "15.67 27\n",
      "191.59 500\n",
      "51.82 37\n",
      "112.15 25\n",
      "17.83 7\n",
      "6.71 7\n",
      "26.71 -3\n",
      "74.83 2\n",
      "584.71 11\n",
      "29.43 154\n",
      "17.91 0\n",
      "333.94 5\n",
      "50.67 136\n",
      "1063.49 61\n",
      "17.28 -7\n",
      "33.13 0\n",
      "16.92 18\n",
      "3.43 11\n",
      "1136.13 5\n",
      "100.83 98\n",
      "27.79 19\n",
      "71.85 42\n",
      "47.56 26\n",
      "604.02 284\n",
      "1924.91 -195\n",
      "54.4 -40\n",
      "392.43 39\n",
      "39.21 7\n",
      "27.36 -12\n",
      "300.67 10\n",
      "56.93 36\n",
      "470.76 0\n",
      "21.92 -1\n",
      "1492.78 -5407\n",
      "82.99 340\n",
      "84.59 7\n",
      "90.37 -11\n",
      "17.27 10\n",
      "55.66 35\n",
      "808.9 595\n",
      "28.86 18\n",
      "17.23 1\n",
      "47.79 127\n",
      "58.85 26\n",
      "75.41 -4\n",
      "470.44 -7\n",
      "59.18 108\n",
      "62.32 9\n",
      "405.21 35\n",
      "10.14 31\n",
      "123.83 -12\n",
      "97.9 -5\n",
      "430.52 9869\n",
      "1431.81 709\n",
      "642.39 670\n",
      "195.61 16\n",
      "35.55 44\n",
      "1756.66 128\n",
      "26.08 1\n",
      "575.23 32\n",
      "11.92 21\n",
      "102.29 39\n",
      "330.91 -8\n",
      "751.23 9256\n",
      "341.98 20\n",
      "25.64 5\n",
      "32.34 141\n",
      "15.5 32\n",
      "71.78 36\n",
      "558.97 51\n",
      "49.84 7\n",
      "45.85 6\n",
      "61.62 0\n",
      "8.83 -16\n",
      "3322.95 -1\n",
      "30.08 18\n",
      "97.35 5\n",
      "57.48 1\n",
      "20.35 39\n",
      "12.41 15\n",
      "14.58 -4\n",
      "116.04 86\n",
      "110.25 1490\n",
      "29.29 21\n",
      "47.9 -3\n",
      "39.21 7\n",
      "35.91 3\n",
      "27.94 12\n",
      "18.44 12\n",
      "43.65 -6\n",
      "233.92 12\n",
      "32.65 6\n",
      "75.94 535\n",
      "24.19 -10\n",
      "5.27 2\n",
      "15.87 11\n",
      "475.43 28\n",
      "595.65 183\n",
      "33.19 36\n",
      "886.41 -24\n",
      "71.33 100\n",
      "28.82 34\n",
      "38.43 0\n",
      "93.42 15\n",
      "798.59 0\n",
      "282.5 20\n",
      "16.49 -3\n",
      "100.59 210\n",
      "643.35 287\n",
      "19.25 21\n",
      "33.7 14\n",
      "4759.67 0\n",
      "39.13 9\n",
      "55.42 -6\n",
      "20.83 0\n",
      "117.34 100\n",
      "1026.67 102\n",
      "66.16 99\n",
      "4570.49 96\n",
      "104.24 117\n",
      "14.83 11\n",
      "142.78 -6\n",
      "43.59 34\n",
      "40.85 4\n",
      "65.39 258\n",
      "14.57 -1\n",
      "4.94 -3\n",
      "41.99 -6\n",
      "66.32 7\n",
      "1475.59 9026\n",
      "59.56 50\n",
      "26.02 6\n",
      "11.08 -6\n",
      "28.94 26\n",
      "2120.38 684\n",
      "11.62 -4\n",
      "30.66 7\n",
      "85.43 9685\n",
      "973.92 8\n",
      "14.58 17\n",
      "816.83 2\n",
      "493.72 47\n",
      "11.48 -2\n",
      "37.46 77\n",
      "338.72 5\n",
      "233.42 14\n",
      "99.55 -7\n",
      "26.71 71\n",
      "74.41 256\n",
      "95.2 3\n",
      "39.02 -4\n",
      "9.21 4\n",
      "15.5 -6\n",
      "16.17 4\n",
      "31.82 -2\n",
      "124.9 9\n",
      "20.77 1\n",
      "728.88 99\n",
      "20.6 21\n",
      "94.77 72\n",
      "384.46 5\n",
      "98.06 337\n",
      "70.4 106\n",
      "2507.56 49\n",
      "57.54 11\n",
      "120.55 79\n",
      "25.71 4\n",
      "37.22 168\n",
      "41.4 100\n",
      "35.59 4\n",
      "41.65 8\n",
      "97.94 0\n",
      "85.35 1\n",
      "81.43 76\n",
      "60.1 226\n",
      "2355.14 -39\n",
      "169.98 -28\n",
      "38.91 22\n",
      "649.15 164\n",
      "134.79 62\n",
      "3894.05 -1\n",
      "824.52 52\n",
      "65.38 -6\n",
      "25.71 38\n",
      "657.0 -394\n",
      "48.54 21\n",
      "795.29 2\n",
      "7.97 47\n",
      "71.68 2\n",
      "11.31 9\n",
      "25.62 8\n",
      "56.73 8\n",
      "8.78 107\n",
      "815.77 5\n",
      "56.5 46\n",
      "872.2 198\n",
      "40.74 16\n",
      "21.92 36\n",
      "174.25 291\n",
      "20.64 48\n",
      "43.7 53\n",
      "10.1 1\n",
      "63.12 31\n",
      "1599.53 0\n",
      "2733.22 -14\n",
      "41.73 16\n",
      "26.54 0\n",
      "15.07 33\n",
      "769.59 1936\n",
      "216.34 9097\n",
      "21.42 -15\n",
      "16.61 33\n",
      "17.25 25\n",
      "19.37 2\n",
      "105.99 6\n",
      "27.93 37\n",
      "45.08 -2\n",
      "23.44 100\n",
      "38.86 26\n",
      "31.49 3\n",
      "52.95 133\n",
      "17.22 0\n",
      "213.79 -4019\n",
      "166.44 0\n",
      "38.0 10\n",
      "25.73 -4\n",
      "65.94 -7\n",
      "8.89 -13\n",
      "45.28 6\n",
      "89.28 24\n",
      "130.17 -7\n",
      "11.59 4\n",
      "153.42 438\n",
      "41.98 23\n",
      "58.67 41\n",
      "22.68 6\n",
      "154.47 4\n",
      "162.2 12\n",
      "137.56 9665\n",
      "43.59 -4\n",
      "727.4 -2\n",
      "54.45 6\n",
      "247.0 773\n",
      "532.48 -92\n",
      "1738.94 -56\n",
      "25.8 18\n",
      "84.47 -10\n",
      "73.36 -8\n",
      "37.44 34\n",
      "832.4 25\n",
      "51.37 123\n",
      "499.19 349\n",
      "47.07 4\n",
      "226.93 62\n",
      "25.67 17\n",
      "78.35 -9\n",
      "73.0 71\n",
      "86.1 53\n",
      "49.77 38\n",
      "274.54 -135\n",
      "19.98 1\n",
      "323.72 21\n",
      "13.01 5\n",
      "107.99 28\n",
      "75.97 -7\n",
      "18.73 12\n",
      "274.53 -4\n",
      "468.92 -1\n",
      "137.1 143\n",
      "9.43 6\n",
      "63.3 10\n",
      "245.97 84\n",
      "12.14 -2\n",
      "18.13 22\n",
      "1030.76 -291\n",
      "887.63 28\n",
      "1776.22 263\n",
      "14.74 32\n",
      "34.15 -3\n",
      "47.86 -1\n",
      "22.24 23\n",
      "35.5 3\n",
      "78.26 171\n",
      "103.03 175\n",
      "259.12 54\n",
      "1118.81 46\n",
      "86.53 25\n",
      "77.53 117\n",
      "42.93 1\n",
      "1178.55 136\n",
      "67.12 131\n",
      "62.61 43\n",
      "19.37 46\n",
      "40.83 -4\n",
      "20.12 66\n",
      "68.03 -2\n",
      "56.19 29\n",
      "12.62 30\n",
      "35.14 -55\n",
      "19.18 15\n",
      "146.24 35\n",
      "197.4 107\n",
      "386.25 -16\n",
      "82.76 58\n",
      "16.95 10\n",
      "108.06 125\n",
      "1568.01 242\n",
      "1239.6 7140\n",
      "24.12 5\n",
      "14.7 0\n",
      "180.93 56\n",
      "30.12 36\n",
      "108.23 114\n",
      "34.47 14\n",
      "77.02 3\n",
      "71.22 -1\n",
      "281.62 0\n",
      "22.37 75\n",
      "1443.07 -1\n",
      "26.06 67\n",
      "9.55 25\n",
      "246.56 13\n",
      "150.57 -3\n",
      "22.23 31\n",
      "49.43 8\n",
      "232.82 9538\n",
      "113.5 15\n",
      "86.9 19\n",
      "1804.79 -1\n",
      "75.87 49\n",
      "1410.58 61\n",
      "43.08 200\n",
      "301.45 4\n",
      "19.79 43\n",
      "99.19 -5\n",
      "132.72 81\n",
      "57.61 8\n",
      "790.3 4707\n",
      "67.29 4\n",
      "271.19 30\n",
      "10.93 25\n",
      "79.84 92\n",
      "2251.65 2\n",
      "89.91 44\n",
      "756.79 2\n",
      "542.33 9449\n",
      "263.5 45\n",
      "32.52 6\n",
      "91.61 -11\n",
      "22.22 17\n",
      "436.38 2\n",
      "70.24 6\n",
      "152.29 87\n",
      "116.98 135\n",
      "60.55 20\n",
      "558.54 9\n",
      "35.43 -4\n",
      "260.76 29\n",
      "39.38 51\n",
      "508.78 355\n",
      "47.53 118\n",
      "38.9 2\n",
      "50.96 -1\n",
      "49.4 17\n",
      "25.26 58\n",
      "2280.26 40\n",
      "22.78 -13\n",
      "316.49 6\n",
      "11.74 7\n",
      "10.21 0\n",
      "45.38 86\n",
      "1517.19 -13\n",
      "368.19 -127\n",
      "13.22 181\n",
      "16.23 3\n",
      "1443.8 113\n",
      "31.69 9\n",
      "66.04 0\n",
      "12.93 4\n",
      "72.66 304\n",
      "185.88 1173\n",
      "67.54 204\n",
      "18.06 2\n",
      "33.5 14\n",
      "106.96 0\n",
      "26.9 6\n",
      "110.4 -6\n",
      "51.05 27\n",
      "2231.04 8\n",
      "67.86 24\n",
      "23.27 -17\n",
      "20.86 5\n",
      "10.35 -2\n",
      "159.85 10\n",
      "1571.42 54\n",
      "2462.56 465\n",
      "31.21 41\n",
      "17.16 23\n",
      "18.04 7\n",
      "335.75 539\n",
      "2721.47 -21\n",
      "104.64 14\n",
      "37.03 378\n",
      "28.5 211\n",
      "194.25 -4\n",
      "95.67 15\n",
      "128.18 125\n",
      "329.92 42\n",
      "221.82 5\n",
      "81.28 116\n",
      "1897.9 -28\n",
      "52.36 -5\n",
      "29.15 5\n",
      "12.38 12\n",
      "26.91 51\n",
      "45.05 28\n",
      "12.64 26\n",
      "146.79 116\n",
      "22.77 11\n",
      "33.05 -4\n",
      "71.35 16\n",
      "16.39 15\n",
      "48.62 10\n",
      "632.36 3\n",
      "17.09 0\n",
      "138.13 15\n",
      "917.25 -148\n",
      "981.97 58\n",
      "98.39 201\n",
      "83.79 99\n",
      "86.2 21\n",
      "46.8 96\n",
      "1643.21 7\n",
      "32.41 7\n",
      "918.94 0\n",
      "91.07 7\n",
      "48.14 7\n",
      "40.81 25\n",
      "127.65 -49\n",
      "1812.63 1\n",
      "43.45 182\n",
      "58.39 -4\n",
      "198.6 5\n",
      "21.36 6\n",
      "17.89 19\n",
      "59.81 0\n",
      "177.75 308\n",
      "89.15 1244\n",
      "49.1 9\n",
      "1100.49 -12\n",
      "1022.75 -1\n",
      "210.11 270\n",
      "32.79 41\n",
      "677.85 1014\n",
      "267.93 143\n",
      "35.79 91\n",
      "163.42 27\n",
      "1212.5 -7\n",
      "12.45 7\n",
      "635.69 0\n",
      "8.82 -3\n",
      "24.34 -3\n",
      "61.79 300\n",
      "17.41 91\n",
      "230.1 299\n",
      "315.0 37\n",
      "205.79 -8\n",
      "203.48 183\n",
      "119.48 25\n",
      "17.75 -5\n",
      "139.39 -10\n",
      "28.67 0\n",
      "101.22 126\n",
      "11.95 41\n",
      "7.05 -1\n",
      "515.16 17\n",
      "640.89 -2\n",
      "22.85 34\n",
      "8.07 9\n",
      "837.51 -15\n",
      "68.44 56\n",
      "24.37 6\n",
      "688.77 31\n",
      "66.01 75\n",
      "650.12 154\n",
      "2803.5 7399\n",
      "336.92 589\n",
      "54.06 44\n",
      "771.87 2\n",
      "29.07 10\n",
      "805.56 479\n",
      "870.78 3162\n",
      "51.01 372\n",
      "34.53 40\n",
      "40.88 -7\n",
      "13.89 12\n",
      "41.52 5\n",
      "58.24 74\n",
      "30.43 78\n",
      "9.66 -8\n",
      "18.73 16\n",
      "20.09 14\n",
      "129.96 2\n",
      "23.56 44\n",
      "159.87 91\n",
      "15.32 7\n",
      "57.39 8\n",
      "36.16 167\n",
      "77.76 19\n",
      "30.09 0\n",
      "-1.14 3\n",
      "210.6 17\n",
      "136.39 21\n",
      "430.34 84\n",
      "25.8 -6\n",
      "55.16 10032\n",
      "735.46 21\n",
      "851.9 7971\n",
      "28.24 1\n",
      "667.66 105\n",
      "27.96 114\n",
      "2138.94 0\n",
      "8.36 25\n",
      "206.59 299\n",
      "26.41 -1\n",
      "1558.27 -4\n",
      "21.38 16\n",
      "225.61 42\n",
      "1166.79 0\n",
      "82.34 -6\n",
      "12.16 2\n",
      "30.13 106\n",
      "227.46 6\n",
      "32.66 -2\n",
      "10.9 -13\n",
      "297.14 4\n",
      "11.81 29\n",
      "495.81 -1\n",
      "14.87 -2\n",
      "149.31 143\n",
      "179.48 10\n",
      "125.11 2\n",
      "42.53 -8\n",
      "54.66 46\n",
      "343.18 1223\n",
      "57.12 -32\n",
      "41.71 17\n",
      "128.87 6\n",
      "51.14 72\n",
      "29.82 6\n",
      "16.78 -114\n",
      "176.5 14\n",
      "442.26 44\n",
      "72.26 117\n",
      "98.25 11\n",
      "13.57 0\n",
      "169.33 62\n",
      "416.71 8644\n",
      "166.67 -1\n",
      "16.19 14\n",
      "85.89 7\n",
      "31.31 43\n",
      "170.44 0\n",
      "53.57 13\n",
      "39.8 61\n",
      "26.59 -3\n",
      "36.26 305\n",
      "151.12 209\n",
      "1241.23 505\n",
      "8.86 5\n",
      "198.51 378\n",
      "176.76 -17\n",
      "15.33 2\n",
      "240.15 5\n",
      "33.14 2\n",
      "1203.38 46\n",
      "195.01 18\n",
      "7.73 -3\n",
      "175.02 -5\n",
      "1543.38 -35\n",
      "15.63 35\n",
      "44.04 -6\n",
      "2567.49 1\n",
      "203.81 261\n",
      "3.94 15\n",
      "208.42 -29\n",
      "56.38 -3\n",
      "16.65 10\n",
      "307.89 -4185\n",
      "41.55 -3\n",
      "128.63 -7\n",
      "40.81 -2\n",
      "435.89 0\n",
      "15.37 22\n",
      "579.54 206\n",
      "125.72 2233\n",
      "318.69 -84\n",
      "363.13 95\n",
      "96.25 29\n",
      "183.67 9268\n",
      "718.56 -15\n",
      "380.01 97\n",
      "67.13 29\n",
      "608.4 48\n",
      "806.04 76\n",
      "5.75 1\n",
      "39.23 34\n",
      "32.37 3\n",
      "623.39 89\n",
      "6.15 12\n",
      "94.33 41\n",
      "59.02 17\n",
      "376.69 3388\n",
      "39.99 44\n",
      "23.02 -10\n",
      "859.43 9016\n",
      "38.97 24\n",
      "7.37 -4\n",
      "45.25 11\n",
      "230.76 6\n",
      "181.63 28\n",
      "49.47 -8\n",
      "10.49 1\n",
      "10.08 61\n",
      "7.08 3\n",
      "1180.31 90\n",
      "17.79 14\n",
      "15.63 3\n",
      "63.36 371\n",
      "56.84 102\n",
      "271.27 3\n",
      "35.94 16\n",
      "15.97 15\n",
      "97.09 262\n",
      "40.09 8\n",
      "45.24 14\n",
      "18.4 15\n",
      "5.89 2\n",
      "68.45 65\n",
      "14.26 -2\n",
      "1876.25 71\n",
      "655.5 185\n",
      "27.14 39\n",
      "23.77 44\n",
      "81.13 28\n",
      "29.86 -1\n",
      "23.42 -12\n",
      "110.16 -59\n",
      "54.84 6\n",
      "41.71 26\n",
      "19.03 -6\n",
      "73.0 11\n",
      "16.37 -9\n",
      "47.52 64\n",
      "27.33 79\n",
      "91.96 -3\n",
      "42.61 -25\n",
      "110.36 1\n",
      "88.84 8\n",
      "34.15 -2\n",
      "19.83 -5\n",
      "8.66 57\n",
      "31.71 10003\n",
      "225.98 33\n",
      "32.67 10\n",
      "101.25 181\n",
      "188.23 294\n",
      "1497.65 0\n",
      "319.72 2\n",
      "11.69 13\n",
      "4.96 10\n",
      "52.0 31\n",
      "370.19 50\n",
      "63.57 59\n",
      "2130.78 1326\n",
      "61.98 7\n",
      "109.11 3\n",
      "54.52 -9\n",
      "50.75 82\n",
      "678.5 0\n",
      "152.87 -2\n",
      "481.34 199\n",
      "17.3 31\n",
      "45.02 124\n",
      "41.12 5\n",
      "251.27 -4\n",
      "1985.62 587\n",
      "33.45 36\n",
      "32.32 14\n",
      "2224.19 3149\n",
      "54.52 13\n",
      "15.93 2\n",
      "35.05 11\n",
      "44.33 -5\n",
      "363.59 120\n",
      "144.61 184\n",
      "47.81 18\n",
      "395.7 14\n",
      "889.61 0\n",
      "27.87 97\n",
      "1072.25 107\n",
      "41.53 53\n",
      "13.52 -2\n",
      "46.7 -14\n",
      "13.65 29\n",
      "60.47 102\n",
      "23.46 1\n",
      "29.15 42\n",
      "243.96 -4\n",
      "167.81 14\n",
      "1489.62 181\n",
      "355.1 29\n",
      "43.56 56\n",
      "14.11 1\n",
      "61.39 8\n",
      "18.91 16\n",
      "19.85 70\n",
      "114.18 328\n",
      "50.93 89\n",
      "12.1 43\n",
      "240.26 -15\n",
      "41.21 11\n",
      "35.31 19\n",
      "39.23 12\n",
      "72.76 22\n",
      "7.22 -3\n",
      "522.12 82\n",
      "131.12 -13\n",
      "138.01 25\n",
      "45.48 -25\n",
      "142.48 -4\n",
      "37.64 -7\n",
      "156.76 21\n",
      "41.64 17\n",
      "8.69 9\n",
      "374.99 65\n",
      "132.58 -552\n",
      "1363.09 18\n",
      "18.62 20\n",
      "177.36 308\n",
      "17.9 21\n",
      "21.34 0\n",
      "194.95 115\n",
      "61.09 500\n",
      "468.47 46\n",
      "13.41 -1\n",
      "292.7 3\n",
      "496.57 -1\n",
      "355.65 9\n",
      "16.45 109\n",
      "46.44 6\n",
      "101.87 28\n",
      "222.92 -8\n",
      "7.46 5\n",
      "53.66 45\n",
      "198.78 12\n",
      "39.79 67\n",
      "31.98 6\n",
      "32.68 96\n",
      "34.44 21\n",
      "1330.6 33\n",
      "96.85 196\n",
      "40.52 8\n",
      "8.57 7\n",
      "56.65 -6\n",
      "41.88 2\n",
      "1604.4 7\n",
      "123.41 -16\n",
      "47.52 25\n",
      "102.47 21\n",
      "111.19 0\n",
      "67.74 -11\n",
      "149.96 20\n",
      "224.12 232\n",
      "742.18 34\n",
      "12.32 14\n",
      "27.84 15\n",
      "1026.47 -1\n",
      "216.49 -5\n",
      "698.08 -4\n",
      "11.0 -5\n",
      "50.8 568\n",
      "48.96 69\n",
      "26.02 11\n",
      "30.77 1\n",
      "26.42 56\n",
      "1565.56 0\n",
      "50.07 5\n",
      "10.99 9\n",
      "39.7 1\n",
      "1950.32 139\n",
      "561.69 225\n",
      "1454.01 846\n",
      "35.43 12\n",
      "154.37 314\n",
      "25.61 -2\n",
      "557.61 1\n",
      "1593.97 0\n",
      "327.12 80\n",
      "437.78 -16\n",
      "63.21 1\n",
      "24.91 110\n",
      "144.06 2\n",
      "63.51 10\n",
      "65.2 12\n",
      "159.74 98\n",
      "36.46 36\n",
      "14.64 -1\n",
      "17.05 0\n",
      "6.76 -4\n",
      "66.16 111\n",
      "15.78 -3\n",
      "437.3 18\n",
      "19.85 62\n",
      "96.93 376\n",
      "17.89 23\n",
      "12.67 19\n",
      "66.69 0\n",
      "55.3 -1\n",
      "41.06 -3\n",
      "16.41 12\n",
      "55.12 8\n",
      "34.57 5\n",
      "46.14 2\n",
      "353.36 79\n",
      "128.66 16\n",
      "66.77 9905\n",
      "31.78 34\n",
      "21.44 20\n",
      "33.06 1\n",
      "96.49 4\n",
      "34.11 25\n",
      "96.97 10\n",
      "193.96 61\n",
      "16.25 5\n",
      "214.19 750\n",
      "24.81 7\n",
      "61.91 0\n",
      "295.32 0\n",
      "3595.28 90\n",
      "24.84 -6\n",
      "34.17 2\n",
      "34.05 8\n",
      "32.7 0\n",
      "30.25 157\n",
      "37.81 75\n",
      "21.81 1\n",
      "393.78 40\n",
      "490.95 88\n",
      "2913.08 573\n",
      "52.37 32\n",
      "537.12 18\n",
      "128.34 13\n",
      "190.86 -71\n",
      "869.23 -1\n",
      "92.21 21\n",
      "10.27 5\n",
      "50.95 24\n",
      "14.41 -2\n",
      "1499.65 -15\n",
      "559.87 10\n",
      "81.48 133\n",
      "30.16 390\n",
      "323.2 9831\n",
      "14.65 13\n",
      "1953.17 3\n",
      "331.36 17\n",
      "18.69 10\n",
      "54.43 41\n",
      "29.61 16\n",
      "1103.08 7484\n",
      "26.52 -4\n",
      "4841.83 -1\n",
      "86.87 99\n",
      "2853.43 56\n",
      "98.79 -3\n",
      "621.32 711\n",
      "213.87 799\n",
      "84.61 -11\n",
      "280.06 0\n",
      "1252.31 -15\n",
      "80.66 -9\n",
      "47.14 97\n",
      "272.33 68\n",
      "143.09 7\n",
      "30.38 36\n",
      "45.89 11\n",
      "28.68 34\n",
      "69.42 802\n",
      "11.73 16\n",
      "214.14 -10\n",
      "18.83 16\n",
      "11.03 236\n",
      "7.52 9\n",
      "31.86 12\n",
      "234.13 927\n",
      "33.8 -1\n",
      "529.18 6\n",
      "49.37 71\n",
      "1313.38 89\n",
      "79.1 168\n",
      "515.86 13\n",
      "80.29 235\n",
      "20.6 -10\n",
      "233.04 15\n",
      "9.43 -5\n",
      "-30.5 19\n",
      "52.77 229\n",
      "722.19 113\n",
      "72.71 329\n",
      "697.46 5031\n",
      "46.88 15\n",
      "43.88 10\n",
      "1293.48 4\n",
      "7.67 7\n",
      "296.91 188\n",
      "48.78 -10\n",
      "3624.74 0\n",
      "405.33 1520\n",
      "63.04 -4\n",
      "14.14 -2\n",
      "14.2 -1\n",
      "21.65 123\n",
      "484.44 62\n",
      "28.69 11\n",
      "1532.35 21\n",
      "19.81 9\n",
      "2841.02 4231\n",
      "223.02 -8\n",
      "223.34 -2\n",
      "82.18 21\n",
      "3422.65 -1\n",
      "273.61 167\n",
      "136.43 -26\n",
      "191.48 -241\n",
      "68.1 134\n",
      "2543.57 414\n",
      "27.92 21\n",
      "309.04 18\n",
      "189.73 105\n",
      "26.08 27\n",
      "53.5 79\n",
      "1541.66 11\n",
      "36.68 0\n",
      "15.73 3\n",
      "286.93 137\n",
      "26.65 31\n",
      "16.03 18\n",
      "67.05 31\n",
      "271.09 -2\n",
      "25.45 53\n",
      "140.24 755\n",
      "72.38 42\n",
      "408.23 118\n",
      "21.64 1\n",
      "303.82 -1\n",
      "673.52 -1\n",
      "18.97 165\n",
      "47.89 84\n",
      "299.61 -20\n",
      "15.72 11\n",
      "35.66 68\n",
      "19.4 -4\n",
      "16.94 2\n",
      "118.54 74\n",
      "17.69 10\n",
      "83.08 99\n",
      "7.87 0\n",
      "60.5 1\n",
      "1940.38 -43\n",
      "22.01 4\n",
      "35.02 14\n",
      "384.33 158\n",
      "20.83 16\n",
      "211.86 208\n",
      "26.39 3\n",
      "41.32 -18\n",
      "421.75 316\n",
      "72.77 -1\n",
      "70.62 -4\n",
      "35.86 47\n",
      "1448.35 -4310\n",
      "31.58 216\n",
      "112.89 181\n",
      "34.53 20\n",
      "216.22 382\n",
      "11.73 19\n",
      "86.03 6\n",
      "196.78 1598\n",
      "81.25 -3\n",
      "335.41 19\n",
      "1760.22 7511\n",
      "64.82 6\n",
      "77.93 12\n",
      "633.15 551\n",
      "177.25 31\n",
      "13.34 84\n",
      "66.11 47\n",
      "2620.91 -1\n",
      "318.12 154\n",
      "44.46 -11\n",
      "15.26 20\n",
      "17.24 2\n",
      "15.66 11\n",
      "31.18 8\n",
      "59.3 4\n",
      "67.78 20\n",
      "57.83 179\n",
      "33.2 -24\n",
      "15.72 31\n",
      "47.1 60\n",
      "95.93 -16\n",
      "613.33 0\n",
      "150.51 123\n",
      "89.07 49\n",
      "373.28 133\n",
      "16.29 10\n",
      "82.96 -1\n",
      "26.18 18\n",
      "157.11 196\n",
      "962.88 0\n",
      "19.82 36\n",
      "51.39 54\n",
      "79.32 68\n",
      "601.07 3\n",
      "19.03 8\n",
      "71.03 180\n",
      "536.55 3049\n",
      "100.16 9\n",
      "50.67 161\n",
      "23.37 53\n",
      "235.33 2\n",
      "60.67 -7\n",
      "14.42 -9\n",
      "0.28 -1\n",
      "36.53 8\n",
      "66.45 65\n",
      "24.29 42\n",
      "129.23 -64\n",
      "633.87 370\n",
      "660.43 -38\n",
      "89.18 2\n",
      "27.58 81\n",
      "1851.54 51\n",
      "83.69 1\n",
      "21.65 9\n",
      "17.77 7\n",
      "23.11 -1\n",
      "4.23 14\n",
      "17.41 232\n",
      "58.96 85\n",
      "39.87 375\n",
      "29.15 1\n",
      "1199.62 20\n",
      "525.45 65\n",
      "21.12 13\n",
      "103.89 32\n",
      "14.09 34\n",
      "66.72 65\n",
      "50.22 44\n",
      "814.16 52\n",
      "30.52 3\n",
      "99.82 15\n",
      "122.87 44\n",
      "16.29 12\n",
      "208.51 9991\n",
      "590.86 61\n",
      "495.45 -1\n",
      "31.34 560\n",
      "367.52 726\n",
      "42.54 51\n",
      "344.17 218\n",
      "54.41 21\n",
      "311.2 -37\n",
      "1231.93 1483\n",
      "226.97 -24\n",
      "20.17 40\n",
      "618.95 67\n",
      "25.12 2\n",
      "26.45 107\n",
      "524.27 89\n",
      "8.66 9\n",
      "47.24 32\n",
      "249.16 81\n",
      "256.12 75\n",
      "173.52 1\n",
      "174.76 135\n",
      "43.56 15\n",
      "34.44 -15\n",
      "19.96 12\n",
      "858.58 4449\n",
      "45.06 57\n",
      "148.3 0\n",
      "7.59 18\n",
      "16.19 19\n",
      "8.13 29\n",
      "700.96 54\n",
      "44.52 8\n",
      "244.08 25\n",
      "65.2 124\n",
      "18.58 2\n",
      "116.75 143\n",
      "110.04 579\n",
      "131.73 14\n",
      "13.42 10\n",
      "30.44 12\n",
      "331.36 204\n",
      "34.37 -4\n",
      "146.58 4\n",
      "68.11 22\n",
      "11.04 7\n",
      "36.89 5\n",
      "17.89 10\n",
      "18.39 16\n",
      "15.16 -2\n",
      "35.1 17\n",
      "13.43 11\n",
      "151.54 44\n",
      "73.16 192\n",
      "927.76 912\n",
      "74.09 147\n",
      "2387.46 8605\n",
      "271.59 15\n",
      "41.66 -4\n",
      "357.55 2\n",
      "34.57 0\n",
      "21.54 45\n",
      "913.5 -13\n",
      "20.11 43\n",
      "12.04 -10\n",
      "142.42 -9\n",
      "716.94 30\n",
      "29.91 139\n",
      "101.42 1\n",
      "22.44 7\n",
      "95.38 63\n",
      "98.68 13\n",
      "28.2 101\n",
      "79.8 160\n",
      "51.46 3\n",
      "19.12 -9\n",
      "18.07 67\n",
      "267.67 0\n",
      "232.52 2\n",
      "37.68 7\n",
      "118.87 1\n",
      "144.9 235\n",
      "327.67 4410\n",
      "103.91 1400\n",
      "15.28 -21\n",
      "42.84 103\n",
      "16.9 18\n",
      "34.87 39\n",
      "23.45 6\n",
      "126.43 -24\n",
      "94.96 12\n",
      "163.65 9452\n",
      "176.82 -17\n",
      "77.57 -34\n",
      "58.88 -7\n",
      "26.2 21\n",
      "62.55 3\n",
      "578.91 535\n",
      "89.85 103\n",
      "33.89 32\n",
      "441.47 1\n",
      "601.42 30\n",
      "179.06 1066\n",
      "890.6 -55\n",
      "44.16 19\n",
      "91.87 220\n",
      "38.87 2\n",
      "1264.67 512\n",
      "24.56 33\n",
      "13.28 4\n",
      "1511.21 2\n",
      "55.49 354\n",
      "13.97 0\n",
      "22.08 3\n",
      "22.85 32\n",
      "27.07 -2\n",
      "1285.55 143\n",
      "33.85 55\n",
      "568.17 10\n",
      "17.72 -8\n",
      "46.46 4\n",
      "23.66 -24\n",
      "8.27 3\n",
      "44.55 -8\n",
      "1205.12 9704\n",
      "50.47 62\n",
      "74.04 30\n",
      "52.92 11\n",
      "41.37 26\n",
      "39.64 8\n",
      "268.32 1\n",
      "22.68 9\n",
      "39.37 1\n",
      "51.77 120\n",
      "2949.24 -12\n",
      "27.72 8\n",
      "23.2 52\n",
      "622.58 -3\n",
      "56.01 51\n",
      "1491.78 1316\n",
      "38.49 31\n",
      "1119.8 86\n",
      "237.87 -3\n",
      "214.37 36\n",
      "1003.59 4\n",
      "616.94 -11\n",
      "74.37 335\n",
      "95.1 3\n",
      "436.64 100\n",
      "213.9 257\n",
      "1127.9 3119\n",
      "98.6 67\n",
      "100.35 41\n",
      "35.19 110\n",
      "3195.95 -1\n",
      "495.16 4\n",
      "113.41 51\n",
      "35.54 79\n",
      "637.54 223\n",
      "61.39 12\n",
      "47.63 0\n",
      "50.18 -2\n",
      "15.72 14\n",
      "12.46 39\n",
      "41.78 153\n",
      "12.02 -1\n",
      "58.63 75\n",
      "105.93 -3\n",
      "31.46 326\n",
      "6.04 0\n",
      "56.75 29\n",
      "19.22 -34\n",
      "29.21 62\n",
      "14.61 15\n",
      "54.18 31\n",
      "25.14 38\n",
      "21.43 20\n",
      "27.28 192\n",
      "148.74 67\n",
      "204.51 10\n",
      "71.54 20\n",
      "211.06 20\n",
      "3374.91 4371\n",
      "83.72 206\n",
      "28.3 -1\n",
      "85.34 23\n",
      "47.07 72\n",
      "10.38 -7\n",
      "76.38 -2\n",
      "14.63 53\n",
      "388.78 247\n",
      "17.35 28\n",
      "27.25 5\n",
      "108.96 1143\n",
      "12.05 18\n",
      "16.14 3\n",
      "12.54 -2\n",
      "121.99 1015\n",
      "22.96 26\n",
      "357.35 122\n",
      "62.06 7\n",
      "1942.55 428\n",
      "32.68 107\n",
      "559.88 33\n",
      "390.23 8\n",
      "613.46 -1\n",
      "15.97 6\n",
      "47.26 94\n",
      "43.27 11\n",
      "63.23 -5\n",
      "16.92 12\n",
      "26.9 116\n",
      "97.46 126\n",
      "1173.2 6\n",
      "45.17 -5\n",
      "457.16 -12\n",
      "536.15 -8\n",
      "1921.44 -1\n",
      "45.54 237\n",
      "80.42 21\n",
      "26.18 -7\n",
      "536.93 211\n",
      "578.03 585\n",
      "784.01 -1\n",
      "91.7 455\n",
      "74.39 10\n",
      "423.71 -1\n",
      "56.93 -2\n",
      "3968.39 0\n",
      "137.87 32\n",
      "15.16 -3\n",
      "5006.87 244\n",
      "58.46 43\n",
      "158.55 0\n",
      "27.85 25\n",
      "14.87 42\n",
      "38.77 54\n",
      "56.04 -31\n",
      "326.53 606\n",
      "265.81 9\n",
      "99.09 123\n",
      "4.33 2\n",
      "33.42 93\n",
      "42.69 -2\n",
      "7.16 2\n",
      "20.74 2\n",
      "200.21 43\n",
      "77.16 29\n",
      "75.98 138\n",
      "9.82 -1\n",
      "61.29 91\n",
      "14.67 -6\n",
      "36.11 114\n",
      "231.31 9\n",
      "1047.21 32\n",
      "797.14 -2\n",
      "33.13 264\n",
      "37.11 3\n",
      "1841.97 8809\n",
      "551.3 492\n",
      "233.74 226\n",
      "37.24 -19\n",
      "19.96 51\n",
      "36.18 87\n",
      "61.95 1240\n",
      "440.17 404\n",
      "610.99 -119\n",
      "751.09 199\n",
      "20.73 65\n",
      "5.89 6\n",
      "152.14 -9\n",
      "80.85 27\n",
      "176.89 553\n",
      "108.4 115\n",
      "23.69 13\n",
      "17.98 19\n",
      "16.95 1\n",
      "15.35 40\n",
      "181.04 -43\n",
      "448.35 -6\n",
      "17.31 20\n",
      "505.48 -36\n",
      "212.79 -11\n",
      "665.73 818\n",
      "39.37 -9\n",
      "26.81 143\n",
      "2264.48 4\n",
      "70.12 185\n",
      "1650.58 145\n",
      "46.58 69\n",
      "45.77 1\n",
      "14.88 1\n",
      "2030.7 164\n",
      "57.72 15\n",
      "38.35 5\n",
      "83.64 4\n",
      "147.56 15\n",
      "1434.28 2\n",
      "487.25 4903\n",
      "31.89 76\n",
      "16.03 15\n",
      "275.42 60\n",
      "53.47 23\n",
      "486.09 23\n",
      "60.75 0\n",
      "644.29 275\n",
      "1067.61 -1\n",
      "35.97 -15\n",
      "37.4 82\n",
      "244.43 1312\n",
      "112.76 -20\n",
      "56.32 1\n",
      "1229.07 834\n",
      "18.39 9\n",
      "67.47 188\n",
      "48.04 9\n",
      "87.77 3\n",
      "488.66 3999\n",
      "43.18 8\n",
      "52.61 6\n",
      "25.18 1\n",
      "248.77 71\n",
      "33.29 9\n",
      "85.24 4\n",
      "11.3 35\n",
      "93.23 49\n",
      "17.1 -9\n",
      "2051.41 -2\n",
      "35.55 22\n",
      "35.92 37\n",
      "87.71 143\n",
      "1054.7 484\n",
      "3.31 -4\n",
      "17.8 -5\n",
      "51.83 69\n",
      "33.46 207\n",
      "59.84 10\n",
      "73.11 65\n",
      "878.64 846\n",
      "96.44 56\n",
      "71.9 41\n",
      "34.38 120\n",
      "12.77 47\n",
      "16.7 84\n",
      "5.53 45\n",
      "102.52 5\n",
      "642.46 -22\n",
      "411.37 -193\n",
      "72.41 92\n",
      "95.87 -11\n",
      "37.24 4\n",
      "24.18 -2\n",
      "246.77 184\n",
      "14.33 25\n",
      "463.89 135\n",
      "72.95 -10\n",
      "1309.07 -1\n",
      "45.6 -2\n",
      "3.31 2\n",
      "19.03 14\n",
      "30.16 148\n",
      "627.2 90\n",
      "61.84 -7\n",
      "197.57 22\n",
      "79.38 -75\n",
      "356.9 174\n",
      "46.35 18\n",
      "27.35 4\n",
      "42.23 15\n",
      "13.97 6\n",
      "90.94 14\n",
      "78.38 3\n",
      "-442.8 194\n",
      "431.75 275\n",
      "47.82 0\n",
      "9.44 -5\n",
      "96.79 16\n",
      "2018.01 8067\n",
      "13.12 57\n",
      "243.56 -30\n",
      "103.9 129\n",
      "43.05 114\n",
      "22.3 52\n",
      "116.56 150\n",
      "21.63 11\n",
      "74.49 511\n",
      "24.47 63\n",
      "405.2 24\n",
      "101.64 29\n",
      "64.39 177\n",
      "57.39 -4\n",
      "26.32 0\n",
      "38.64 28\n",
      "43.06 210\n",
      "24.75 5\n",
      "50.39 5\n",
      "34.22 93\n",
      "183.93 -3\n",
      "10.32 75\n",
      "48.42 3\n",
      "33.34 -5\n",
      "494.61 12\n",
      "36.52 1\n",
      "47.02 -10\n",
      "47.45 350\n",
      "177.5 -7\n",
      "248.59 151\n",
      "64.34 14\n",
      "15.67 -8\n",
      "55.56 5\n",
      "108.92 362\n",
      "47.51 135\n",
      "11.85 5\n",
      "153.54 19\n",
      "77.3 505\n",
      "14.06 0\n",
      "62.37 -5\n",
      "816.75 -28\n",
      "113.17 -38\n",
      "91.48 239\n",
      "23.26 19\n",
      "3011.96 6\n",
      "132.78 -8\n",
      "159.82 488\n",
      "8.14 8\n",
      "279.66 7863\n",
      "16.28 21\n",
      "63.24 0\n",
      "34.43 -12\n",
      "217.05 106\n",
      "48.71 70\n",
      "50.61 42\n",
      "69.86 353\n",
      "40.79 21\n",
      "51.89 8\n",
      "6251.22 9772\n",
      "16.26 73\n",
      "2246.67 232\n",
      "-113.64 22\n",
      "63.84 130\n",
      "75.9 -1\n",
      "29.36 0\n",
      "23.33 96\n",
      "34.67 5\n",
      "43.1 -3\n",
      "23.91 1\n",
      "34.87 158\n",
      "38.65 9934\n",
      "105.76 43\n",
      "188.88 169\n",
      "27.19 -11\n",
      "20.51 1\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(y_test[:3000])):\n",
    "    print(y_pred[i], y_test[i])\n",
    "\n",
    "# len(data[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# Delete vars to save memory for the next tests\n",
    "del X_train, X_test, X_val, y_train, y_test, y_val"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test 2: MLP Neural Network\n",
    "Use only numeric features (not the board state)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Prepare Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000000it [00:04, 248356.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting CSV rows to np.arrays...done.\n"
     ]
    }
   ],
   "source": [
    "''' Load data '''\n",
    "X, y = load_moves_data(csv_filename=data_filename,\n",
    "                       sample_size=150_000,\n",
    "                       include_numeric=True,\n",
    "                       include_fens=False,\n",
    "                       include_target=True,\n",
    "                       split_X_y=True)\n",
    "\n",
    "''' Feature scaling '''\n",
    "# Taken from https://machinelearningmastery.com/how-to-improve-neural-network-stability-and-modeling-performance-with-data-scaling/\n",
    "scaler = skl.preprocessing.MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# TODO not sure if target col should be scaled\n",
    "# scaler = skl.preprocessing.MinMaxScaler()\n",
    "# y_scaled = scaler.fit_transform(y.reshape((-1, 1))).ravel()\n",
    "\n",
    "''' Train/test/validate split '''\n",
    "# X_train, X_test_and_val, y_train, y_test_and_val = train_test_split(X_scaled, y_scaled, test_size=0.3, random_state=0)\n",
    "X_train, X_test_and_val, y_train, y_test_and_val = train_test_split(X_scaled, y, test_size=0.3, random_state=0)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test_and_val, y_test_and_val, test_size=0.5, random_state=0)\n",
    "\n",
    "''' Delete unneeded vars '''\n",
    "del X, y, X_test_and_val, y_test_and_val, X_scaled#, y_scaled"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (70000, 8, 8, 12)\n",
      "X_test.shape: (15000, 8, 8, 12)\n",
      "X_val.shape: (15000, 8, 8, 12)\n",
      "y_train.shape: (70000,)\n",
      "y_test.shape: (15000,)\n",
      "y_val.shape: (15000,)\n"
     ]
    }
   ],
   "source": [
    "# Check shapes\n",
    "print(f'X_train.shape: {X_train.shape}')\n",
    "print(f'X_test.shape: {X_test.shape}')\n",
    "print(f'X_val.shape: {X_val.shape}')\n",
    "print(f'y_train.shape: {y_train.shape}')\n",
    "print(f'y_test.shape: {y_test.shape}')\n",
    "print(f'y_val.shape: {y_val.shape}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Fit Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_136\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_263 (Dense)            (None, 256)               18944     \n",
      "_________________________________________________________________\n",
      "batch_normalization_101 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_273 (LeakyReLU)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_79 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_264 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_102 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_274 (LeakyReLU)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_80 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_265 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_103 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_275 (LeakyReLU)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_81 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_266 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_104 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_276 (LeakyReLU)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_82 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_267 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 220,673\n",
      "Trainable params: 218,625\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp = ks.models.Sequential()\n",
    "mlp.add(ks.layers.InputLayer(input_shape=(X_train.shape[1:])))\n",
    "for _ in range(4):\n",
    "    mlp.add(ks.layers.Dense(256, kernel_initializer='normal'))\n",
    "    mlp.add(ks.layers.BatchNormalization())\n",
    "    mlp.add(ks.layers.LeakyReLU(alpha=0.3))\n",
    "    mlp.add(ks.layers.Dropout(0.8))\n",
    "mlp.add(ks.layers.Dense(1, activation='linear'))\n",
    "\n",
    "mlp.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3282/3282 [==============================] - 26s 7ms/step - loss: 251.9341 - mean_absolute_error: 251.9341 - val_loss: 236.9386 - val_mean_absolute_error: 236.9386\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 236.93863, saving model to weights.01-236.94.hdf5\n",
      "Epoch 2/10\n",
      "3282/3282 [==============================] - 23s 7ms/step - loss: 251.6587 - mean_absolute_error: 251.6587 - val_loss: 236.3599 - val_mean_absolute_error: 236.3599\n",
      "\n",
      "Epoch 00002: val_loss improved from 236.93863 to 236.35991, saving model to weights.02-236.36.hdf5\n",
      "Epoch 3/10\n",
      "3282/3282 [==============================] - 23s 7ms/step - loss: 251.6389 - mean_absolute_error: 251.6389 - val_loss: 236.1501 - val_mean_absolute_error: 236.1501\n",
      "\n",
      "Epoch 00003: val_loss improved from 236.35991 to 236.15009, saving model to weights.03-236.15.hdf5\n",
      "Epoch 4/10\n",
      "3282/3282 [==============================] - 24s 7ms/step - loss: 251.6300 - mean_absolute_error: 251.6300 - val_loss: 236.3561 - val_mean_absolute_error: 236.3561\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 236.15009\n",
      "Epoch 5/10\n",
      "3282/3282 [==============================] - 23s 7ms/step - loss: 251.5650 - mean_absolute_error: 251.5650 - val_loss: 236.1112 - val_mean_absolute_error: 236.1112\n",
      "\n",
      "Epoch 00005: val_loss improved from 236.15009 to 236.11118, saving model to weights.05-236.11.hdf5\n",
      "Epoch 6/10\n",
      "3282/3282 [==============================] - 25s 8ms/step - loss: 251.5686 - mean_absolute_error: 251.5686 - val_loss: 236.3658 - val_mean_absolute_error: 236.3658\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 236.11118\n",
      "Epoch 7/10\n",
      "3282/3282 [==============================] - 21s 6ms/step - loss: 251.5070 - mean_absolute_error: 251.5070 - val_loss: 236.0828 - val_mean_absolute_error: 236.0828\n",
      "\n",
      "Epoch 00007: val_loss improved from 236.11118 to 236.08282, saving model to weights.07-236.08.hdf5\n",
      "Epoch 8/10\n",
      "3282/3282 [==============================] - 21s 7ms/step - loss: 251.5220 - mean_absolute_error: 251.5220 - val_loss: 236.0932 - val_mean_absolute_error: 236.0932\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 236.08282\n",
      "Epoch 9/10\n",
      "3282/3282 [==============================] - 22s 7ms/step - loss: 251.5077 - mean_absolute_error: 251.5077 - val_loss: 236.1058 - val_mean_absolute_error: 236.1058\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 236.08282\n",
      "Epoch 10/10\n",
      "3282/3282 [==============================] - 22s 7ms/step - loss: 251.4961 - mean_absolute_error: 251.4961 - val_loss: 236.0605 - val_mean_absolute_error: 236.0605\n",
      "\n",
      "Epoch 00010: val_loss improved from 236.08282 to 236.06049, saving model to weights.10-236.06.hdf5\n"
     ]
    }
   ],
   "source": [
    "# mlp.load_weights('mlp_weights.10-236.06.hdf5')\n",
    "\n",
    "mlp.compile(optimizer=ks.optimizers.Adam(learning_rate=0.01),\n",
    "              # optimizer=ks.optimizers.Adam(learning_rate=0.005),\n",
    "              loss=ks.losses.MeanAbsoluteError(),\n",
    "              metrics=[ks.metrics.MeanAbsoluteError()])\n",
    "\n",
    "# Callback to save the best model weights\n",
    "checkpoint = ks.callbacks.ModelCheckpoint(\n",
    "    'mlp_weights.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode='auto')\n",
    "\n",
    "# This will start the training and save each epoch output in the history list\n",
    "mlp_history = mlp.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_val, y_val), callbacks=[checkpoint])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(mlp_history.history['mean_absolute_error'], label='mean_absolute_error')\n",
    "plt.plot(mlp_history.history['val_mean_absolute_error'], label='val_mean_absolute_error')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "outputs": [],
   "source": [
    "# Delete vars to save memory for the next tests\n",
    "del X_train, X_test, X_val, y_train, y_test, y_val"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test 3: Convolutional Neural Network\n",
    "Only use one-hot encoded board state as features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Prepare Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000000it [00:03, 259170.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting CSV rows to np.arrays...done.\n",
      "Vectorizing FENs...done.\n"
     ]
    }
   ],
   "source": [
    "''' Load data '''\n",
    "X, y = load_moves_data(csv_filename=data_filename,\n",
    "                       sample_size=100_000,\n",
    "                       include_numeric=False,\n",
    "                       include_fens=True,\n",
    "                       vectorize_fens=True,\n",
    "                       include_target=True,\n",
    "                       split_X_y=True)\n",
    "\n",
    "''' Feature scaling '''\n",
    "# TODO not sure if target col should be scaled?\n",
    "# scaler = skl.preprocessing.MinMaxScaler()\n",
    "# y_scaled = scaler.fit_transform(y.reshape((-1, 1))).ravel()\n",
    "\n",
    "''' Train/test/validate split '''\n",
    "# X_train, X_test_and_val, y_train, y_test_and_val = train_test_split(X, y_scaled, test_size=0.3, random_state=0)\n",
    "X_train, X_test_and_val, y_train, y_test_and_val = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test_and_val, y_test_and_val, test_size=0.5, random_state=0)\n",
    "\n",
    "''' Delete unneeded vars '''\n",
    "del X, y, X_test_and_val, y_test_and_val#, y_scaled"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (70000, 8, 8, 12)\n",
      "X_test.shape: (15000, 8, 8, 12)\n",
      "X_val.shape: (15000, 8, 8, 12)\n",
      "y_train.shape: (70000,)\n",
      "y_test.shape: (15000,)\n",
      "y_val.shape: (15000,)\n"
     ]
    }
   ],
   "source": [
    "# Check shapes\n",
    "print(f'X_train.shape: {X_train.shape}')\n",
    "print(f'X_test.shape: {X_test.shape}')\n",
    "print(f'X_val.shape: {X_val.shape}')\n",
    "print(f'y_train.shape: {y_train.shape}')\n",
    "print(f'y_test.shape: {y_test.shape}')\n",
    "print(f'y_val.shape: {y_val.shape}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Fit Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 8, 8, 64)          6976      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 2, 2, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 200)               51400     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 430,193\n",
      "Trainable params: 428,897\n",
      "Non-trainable params: 1,296\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn = ks.models.Sequential([\n",
    "    ks.layers.InputLayer((8, 8, 12)),\n",
    "\n",
    "    ks.layers.Conv2D(64, 3, padding='same'),\n",
    "    ks.layers.BatchNormalization(),\n",
    "    ks.layers.LeakyReLU(),\n",
    "    # ks.layers.Dropout(0.8),\n",
    "    ks.layers.MaxPool2D(),\n",
    "\n",
    "    ks.layers.Conv2D(128, 3, padding='same'),\n",
    "    ks.layers.BatchNormalization(),\n",
    "    ks.layers.LeakyReLU(),\n",
    "    # ks.layers.Dropout(0.7),\n",
    "    ks.layers.MaxPool2D(),\n",
    "\n",
    "    ks.layers.Conv2D(256, 3, padding='same'),\n",
    "    ks.layers.BatchNormalization(),\n",
    "    ks.layers.LeakyReLU(),\n",
    "    # ks.layers.Dropout(0.6),\n",
    "    ks.layers.MaxPool2D(),\n",
    "\n",
    "    ks.layers.Flatten(),\n",
    "\n",
    "    ks.layers.Dense(200),\n",
    "    ks.layers.BatchNormalization(),\n",
    "    ks.layers.LeakyReLU(),\n",
    "    ks.layers.Dropout(0.8),\n",
    "\n",
    "    # ks.layers.Dense(200),\n",
    "    # ks.layers.BatchNormalization(),\n",
    "    # ks.layers.LeakyReLU(),\n",
    "    # ks.layers.Dropout(0.5),\n",
    "    #\n",
    "    # ks.layers.Dense(200),\n",
    "    # ks.layers.BatchNormalization(),\n",
    "    # ks.layers.LeakyReLU(),\n",
    "    # ks.layers.Dropout(0.5),\n",
    "\n",
    "    ks.layers.Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "cnn.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1094/1094 [==============================] - 31s 27ms/step - loss: 243.3553 - mean_absolute_error: 243.3553 - val_loss: 251.6395 - val_mean_absolute_error: 251.6395\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 251.63953, saving model to cnn_weights.01-251.64.hdf5\n",
      "Epoch 2/500\n",
      "1094/1094 [==============================] - 26s 24ms/step - loss: 242.9835 - mean_absolute_error: 242.9835 - val_loss: 252.5662 - val_mean_absolute_error: 252.5662\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 251.63953\n",
      "Epoch 3/500\n",
      "1094/1094 [==============================] - 26s 24ms/step - loss: 242.7895 - mean_absolute_error: 242.7895 - val_loss: 251.3880 - val_mean_absolute_error: 251.3880\n",
      "\n",
      "Epoch 00003: val_loss improved from 251.63953 to 251.38805, saving model to cnn_weights.03-251.39.hdf5\n",
      "Epoch 4/500\n",
      "1094/1094 [==============================] - 26s 24ms/step - loss: 242.5309 - mean_absolute_error: 242.5309 - val_loss: 251.4529 - val_mean_absolute_error: 251.4529\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 251.38805\n",
      "Epoch 5/500\n",
      "1094/1094 [==============================] - 26s 24ms/step - loss: 242.2514 - mean_absolute_error: 242.2514 - val_loss: 251.6292 - val_mean_absolute_error: 251.6292\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 251.38805\n",
      "Epoch 6/500\n",
      "1094/1094 [==============================] - 27s 24ms/step - loss: 241.8713 - mean_absolute_error: 241.8713 - val_loss: 251.8694 - val_mean_absolute_error: 251.8694\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 251.38805\n",
      "Epoch 7/500\n",
      "1094/1094 [==============================] - 26s 24ms/step - loss: 241.3293 - mean_absolute_error: 241.3293 - val_loss: 251.9523 - val_mean_absolute_error: 251.9523\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 251.38805\n",
      "Epoch 8/500\n",
      "1094/1094 [==============================] - 27s 25ms/step - loss: 240.5497 - mean_absolute_error: 240.5497 - val_loss: 253.9283 - val_mean_absolute_error: 253.9283\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 251.38805\n",
      "Epoch 9/500\n",
      "1094/1094 [==============================] - 27s 25ms/step - loss: 239.7275 - mean_absolute_error: 239.7275 - val_loss: 252.3690 - val_mean_absolute_error: 252.3690\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 251.38805\n",
      "Epoch 10/500\n",
      "1094/1094 [==============================] - 26s 24ms/step - loss: 238.8996 - mean_absolute_error: 238.8996 - val_loss: 253.8988 - val_mean_absolute_error: 253.8988\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 251.38805\n",
      "Epoch 11/500\n",
      "1094/1094 [==============================] - 27s 25ms/step - loss: 237.5985 - mean_absolute_error: 237.5985 - val_loss: 252.7216 - val_mean_absolute_error: 252.7216\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 251.38805\n",
      "Epoch 12/500\n",
      "1094/1094 [==============================] - 27s 25ms/step - loss: 236.4620 - mean_absolute_error: 236.4620 - val_loss: 253.8781 - val_mean_absolute_error: 253.8781\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 251.38805\n",
      "Epoch 13/500\n",
      "1094/1094 [==============================] - 27s 25ms/step - loss: 235.3888 - mean_absolute_error: 235.3888 - val_loss: 264.8034 - val_mean_absolute_error: 264.8034\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 251.38805\n",
      "Epoch 14/500\n",
      "1094/1094 [==============================] - 27s 25ms/step - loss: 234.1653 - mean_absolute_error: 234.1653 - val_loss: 266.5617 - val_mean_absolute_error: 266.5617\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 251.38805\n",
      "Epoch 15/500\n",
      "1094/1094 [==============================] - 27s 25ms/step - loss: 232.9899 - mean_absolute_error: 232.9899 - val_loss: 253.9055 - val_mean_absolute_error: 253.9055\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 251.38805\n",
      "Epoch 16/500\n",
      "1094/1094 [==============================] - 25s 23ms/step - loss: 232.0246 - mean_absolute_error: 232.0246 - val_loss: 254.0812 - val_mean_absolute_error: 254.0812\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 251.38805\n",
      "Epoch 17/500\n",
      "1094/1094 [==============================] - 26s 24ms/step - loss: 230.6836 - mean_absolute_error: 230.6836 - val_loss: 255.2285 - val_mean_absolute_error: 255.2285\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 251.38805\n",
      "Epoch 18/500\n",
      "1094/1094 [==============================] - 25s 23ms/step - loss: 230.1341 - mean_absolute_error: 230.1341 - val_loss: 258.1088 - val_mean_absolute_error: 258.1088\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 251.38805\n",
      "Epoch 19/500\n",
      "1094/1094 [==============================] - 25s 23ms/step - loss: 228.6122 - mean_absolute_error: 228.6122 - val_loss: 270.8434 - val_mean_absolute_error: 270.8434\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 251.38805\n",
      "Epoch 20/500\n",
      "1094/1094 [==============================] - 26s 24ms/step - loss: 227.8050 - mean_absolute_error: 227.8050 - val_loss: 269.0033 - val_mean_absolute_error: 269.0033\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 251.38805\n",
      "Epoch 21/500\n",
      "1094/1094 [==============================] - 25s 23ms/step - loss: 226.9349 - mean_absolute_error: 226.9349 - val_loss: 256.1954 - val_mean_absolute_error: 256.1954\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 251.38805\n",
      "Epoch 22/500\n",
      "1094/1094 [==============================] - 26s 24ms/step - loss: 225.8137 - mean_absolute_error: 225.8137 - val_loss: 265.6910 - val_mean_absolute_error: 265.6910\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 251.38805\n",
      "Epoch 23/500\n",
      "1094/1094 [==============================] - 26s 23ms/step - loss: 225.0585 - mean_absolute_error: 225.0585 - val_loss: 270.0758 - val_mean_absolute_error: 270.0758\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 251.38805\n",
      "Epoch 24/500\n",
      "1094/1094 [==============================] - 25s 23ms/step - loss: 224.1332 - mean_absolute_error: 224.1332 - val_loss: 258.9734 - val_mean_absolute_error: 258.9734\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 251.38805\n",
      "Epoch 25/500\n",
      "1094/1094 [==============================] - 25s 23ms/step - loss: 223.4265 - mean_absolute_error: 223.4265 - val_loss: 263.1454 - val_mean_absolute_error: 263.1454\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 251.38805\n",
      "Epoch 26/500\n",
      "1094/1094 [==============================] - 26s 24ms/step - loss: 222.4486 - mean_absolute_error: 222.4486 - val_loss: 261.8993 - val_mean_absolute_error: 261.8993\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 251.38805\n",
      "Epoch 27/500\n",
      "1094/1094 [==============================] - 26s 23ms/step - loss: 220.9883 - mean_absolute_error: 220.9883 - val_loss: 259.8339 - val_mean_absolute_error: 259.8339\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 251.38805\n",
      "Epoch 28/500\n",
      "1094/1094 [==============================] - 26s 24ms/step - loss: 219.7365 - mean_absolute_error: 219.7365 - val_loss: 285.1588 - val_mean_absolute_error: 285.1588\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 251.38805\n",
      "Epoch 29/500\n",
      "1094/1094 [==============================] - 26s 24ms/step - loss: 218.7735 - mean_absolute_error: 218.7735 - val_loss: 280.2362 - val_mean_absolute_error: 280.2362\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 251.38805\n",
      "Epoch 30/500\n",
      "1094/1094 [==============================] - 26s 24ms/step - loss: 218.1713 - mean_absolute_error: 218.1713 - val_loss: 297.1949 - val_mean_absolute_error: 297.1949\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 251.38805\n",
      "Epoch 31/500\n",
      "1094/1094 [==============================] - 25s 23ms/step - loss: 214.2124 - mean_absolute_error: 214.2124 - val_loss: 333.2439 - val_mean_absolute_error: 333.2439\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 251.38805\n",
      "Epoch 32/500\n",
      "1094/1094 [==============================] - 26s 23ms/step - loss: 211.1745 - mean_absolute_error: 211.1745 - val_loss: 335.8377 - val_mean_absolute_error: 335.8377\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 251.38805\n",
      "Epoch 33/500\n",
      "1094/1094 [==============================] - 26s 23ms/step - loss: 208.8847 - mean_absolute_error: 208.8847 - val_loss: 347.2164 - val_mean_absolute_error: 347.2164\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 251.38805\n",
      "Epoch 34/500\n",
      "1094/1094 [==============================] - 26s 24ms/step - loss: 206.4325 - mean_absolute_error: 206.4325 - val_loss: 297.0777 - val_mean_absolute_error: 297.0777\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 251.38805\n",
      "Epoch 35/500\n",
      "1094/1094 [==============================] - 26s 23ms/step - loss: 201.5973 - mean_absolute_error: 201.5973 - val_loss: 286.6681 - val_mean_absolute_error: 286.6681\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 251.38805\n",
      "Epoch 36/500\n",
      "1094/1094 [==============================] - 26s 23ms/step - loss: 199.5641 - mean_absolute_error: 199.5641 - val_loss: 270.7908 - val_mean_absolute_error: 270.7908\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 251.38805\n",
      "Epoch 37/500\n",
      "1094/1094 [==============================] - 26s 23ms/step - loss: 196.1776 - mean_absolute_error: 196.1776 - val_loss: 320.5655 - val_mean_absolute_error: 320.5655\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 251.38805\n",
      "Epoch 38/500\n",
      "1094/1094 [==============================] - 26s 23ms/step - loss: 195.3989 - mean_absolute_error: 195.3989 - val_loss: 273.9166 - val_mean_absolute_error: 273.9166\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 251.38805\n",
      "Epoch 39/500\n",
      "1094/1094 [==============================] - 26s 24ms/step - loss: 193.6841 - mean_absolute_error: 193.6841 - val_loss: 282.6961 - val_mean_absolute_error: 282.6961\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 251.38805\n",
      "Epoch 40/500\n",
      "1094/1094 [==============================] - 26s 23ms/step - loss: 188.5643 - mean_absolute_error: 188.5643 - val_loss: 293.7321 - val_mean_absolute_error: 293.7321\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 251.38805\n",
      "Epoch 41/500\n",
      "1094/1094 [==============================] - 25s 23ms/step - loss: 190.8442 - mean_absolute_error: 190.8442 - val_loss: 299.8128 - val_mean_absolute_error: 299.8128\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 251.38805\n",
      "Epoch 42/500\n",
      "1094/1094 [==============================] - 26s 24ms/step - loss: 190.4454 - mean_absolute_error: 190.4454 - val_loss: 284.6094 - val_mean_absolute_error: 284.6094\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 251.38805\n",
      "Epoch 43/500\n",
      "1094/1094 [==============================] - 26s 24ms/step - loss: 189.7367 - mean_absolute_error: 189.7367 - val_loss: 256.4225 - val_mean_absolute_error: 256.4225\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 251.38805\n",
      "Epoch 44/500\n",
      "1094/1094 [==============================] - 25s 23ms/step - loss: 187.6044 - mean_absolute_error: 187.6044 - val_loss: 267.7636 - val_mean_absolute_error: 267.7636\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 251.38805\n",
      "Epoch 45/500\n",
      "1094/1094 [==============================] - 26s 24ms/step - loss: 188.4980 - mean_absolute_error: 188.4980 - val_loss: 261.5015 - val_mean_absolute_error: 261.5015\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 251.38805\n",
      "Epoch 46/500\n",
      "1094/1094 [==============================] - 25s 23ms/step - loss: 187.3168 - mean_absolute_error: 187.3168 - val_loss: 373.1702 - val_mean_absolute_error: 373.1702\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 251.38805\n",
      "Epoch 47/500\n",
      "1094/1094 [==============================] - 26s 24ms/step - loss: 183.8585 - mean_absolute_error: 183.8585 - val_loss: 279.6545 - val_mean_absolute_error: 279.6545\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 251.38805\n",
      "Epoch 48/500\n",
      "1094/1094 [==============================] - 26s 24ms/step - loss: 184.3384 - mean_absolute_error: 184.3384 - val_loss: 278.9947 - val_mean_absolute_error: 278.9947\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 251.38805\n",
      "Epoch 49/500\n",
      "1094/1094 [==============================] - 26s 23ms/step - loss: 185.4121 - mean_absolute_error: 185.4121 - val_loss: 274.1993 - val_mean_absolute_error: 274.1993\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 251.38805\n",
      "Epoch 50/500\n",
      "1094/1094 [==============================] - 25s 23ms/step - loss: 184.0565 - mean_absolute_error: 184.0565 - val_loss: 330.9111 - val_mean_absolute_error: 330.9111\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 251.38805\n",
      "Epoch 51/500\n",
      "1094/1094 [==============================] - 25s 23ms/step - loss: 183.4640 - mean_absolute_error: 183.4640 - val_loss: 260.4856 - val_mean_absolute_error: 260.4856\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 251.38805\n",
      "Epoch 52/500\n",
      "1094/1094 [==============================] - 25s 23ms/step - loss: 182.7152 - mean_absolute_error: 182.7152 - val_loss: 272.0763 - val_mean_absolute_error: 272.0763\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 251.38805\n",
      "Epoch 53/500\n",
      "1094/1094 [==============================] - 25s 23ms/step - loss: 181.7597 - mean_absolute_error: 181.7597 - val_loss: 268.3809 - val_mean_absolute_error: 268.3809\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 251.38805\n"
     ]
    }
   ],
   "source": [
    "# cnn.load_weights('cnn_weights.04-219.44.hdf5')\n",
    "\n",
    "cnn.compile(optimizer=ks.optimizers.Adam(learning_rate=0.01),\n",
    "            loss=ks.losses.MeanAbsoluteError(),\n",
    "            metrics=[ks.metrics.MeanAbsoluteError()])\n",
    "\n",
    "# Callback to save the best model weights\n",
    "cnn_checkpoint = ks.callbacks.ModelCheckpoint(\n",
    "    'cnn_weights.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode='auto')\n",
    "\n",
    "# Callback to stop when loss stops increasing\n",
    "cnn_early_stopping = ks.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=50)\n",
    "\n",
    "# This will start the training and save each epoch output in the history list\n",
    "cnn_history = cnn.fit(X_train, y_train,\n",
    "                      batch_size=64,\n",
    "                      epochs=500,\n",
    "                      validation_data=(X_val, y_val),\n",
    "                      callbacks=[cnn_checkpoint, cnn_early_stopping])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cnn_history.history['mean_absolute_error'], label='mean_absolute_error')\n",
    "plt.plot(cnn_history.history['val_mean_absolute_error'], label='val_mean_absolute_error')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}